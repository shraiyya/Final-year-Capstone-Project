{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "200,2 data - 1 layers set reduction - 4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/radhikasethi2011/SilencerEnhancerPredict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsGdEyz9ej92",
        "outputId": "344e2634-6aa2-4db6-af3c-8b4ff0f643fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SilencerEnhancerPredict'...\n",
            "remote: Enumerating objects: 312, done.\u001b[K\n",
            "remote: Counting objects: 100% (312/312), done.\u001b[K\n",
            "remote: Compressing objects: 100% (276/276), done.\u001b[K\n",
            "remote: Total 312 (delta 154), reused 68 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (312/312), 151.06 MiB | 18.11 MiB/s, done.\n",
            "Resolving deltas: 100% (154/154), done.\n",
            "Checking out files: 100% (54/54), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/SilencerEnhancerPredict/examples/"
      ],
      "metadata": {
        "id": "iulfH4gnhoxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4458d871-4f38-4b31-d847-446784ef894c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SilencerEnhancerPredict/examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from sklearn import metrics\n",
        "import h5py\n",
        "import os"
      ],
      "metadata": {
        "id": "SCMSlHzvoM7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_LENGTH = 200\n",
        "EPOCH = 200\n",
        "BATCH_SIZE = 64\n",
        "WORK_DIR = \"./\""
      ],
      "metadata": {
        "id": "909G7HHhqf0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------\n"
      ],
      "metadata": {
        "id": "Apk8No7Sj-Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('model.hdf5')"
      ],
      "metadata": {
        "id": "-zQSwuaJh4il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYNvJsv7leZ_",
        "outputId": "32f0656e-1141-4409-a80f-e88cdd23902b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 992, 480)          17760     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 992, 480)         1920      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 992, 480)          0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 328, 480)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 328, 480)          0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 325, 480)          922080    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 325, 480)         1920      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 325, 480)          0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 161, 480)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 161, 480)          0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 158, 240)          461040    \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 52, 240)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 52, 240)           0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 49, 320)           307520    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 49, 320)          1280      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 49, 320)           0         \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 16, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 13, 320)           409920    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 13, 320)          1280      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 13, 320)           0         \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 4, 320)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 180)               230580    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 543       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,355,843\n",
            "Trainable params: 2,352,643\n",
            "Non-trainable params: 3,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqk45uRWaH0k",
        "outputId": "4114d8a7-ad5c-442a-8b6d-6dbfa5d18a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 1000, 4),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'conv1d_1_input',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 1000, 4),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (9,),\n",
              "    'name': 'conv1d_1',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_1',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_1',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_1',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (9,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_1',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 0.9}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_2',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_2',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_2',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_2',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (2,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_2',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 240,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_3',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_3',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_3',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 320,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_4',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_3',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_3',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_4',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 320,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_5',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_4',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_4',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_5',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Flatten',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'flatten_1',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'sigmoid',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense_1',\n",
              "    'trainable': True,\n",
              "    'units': 180,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'softmax',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense_2',\n",
              "    'trainable': True,\n",
              "    'units': 3,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_file = os.path.join('./examples', \"model_weights.hdf5\")\n",
        "model_file = os.path.join('./examples', \"single_model.hdf5\")\n",
        "model.save(model_file)"
      ],
      "metadata": {
        "id": "VQEkjHcMqAVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afb074b-86d8-4aba-cf90-668631ae7f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_config"
      ],
      "metadata": {
        "id": "tg3r-08QGljQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d66163-9f61-4895-c3a3-dcba4aa9a877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Sequential.get_config of <keras.engine.sequential.Sequential object at 0x7f0f15ba9ed0>>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adadelta()"
      ],
      "metadata": {
        "id": "gsHsFed5op0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODE BASED ON PAPER:"
      ],
      "metadata": {
        "id": "3fA5aQAN38dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import InputLayer, LeakyReLU\n",
        "\n",
        "model1 = Sequential(InputLayer(batch_input_shape= (None, 200, 4),\n",
        "    dtype= 'float32',\n",
        "    ragged= False,\n",
        "    sparse= False))\n",
        "\n",
        "model1.add(Conv1D(activation= 'relu',\n",
        "    activity_regularizer= None,\n",
        "    batch_input_shape= (None, 200, 4),\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer= None,\n",
        "    data_format= 'channels_last',\n",
        "    dilation_rate= (1,),\n",
        "    dtype= 'float32',\n",
        "    filters= 480,\n",
        "    groups= 1,\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
        "    kernel_size= (9,),\n",
        "    padding= 'valid',\n",
        "    strides= (1,),\n",
        "    trainable= True,\n",
        "    use_bias= True))\n",
        "\n",
        "model1.add(BatchNormalization(\n",
        "    beta_constraint= None,\n",
        "    beta_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    beta_regularizer= None,\n",
        "    center= True,\n",
        "    dtype= 'float32',\n",
        "    epsilon= 0.001,\n",
        "    gamma_constraint= None,\n",
        "    gamma_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    gamma_regularizer= None,\n",
        "    momentum= 0.99,\n",
        "    moving_mean_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    moving_variance_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    scale= True,\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(LeakyReLU(alpha= 0.0,\n",
        "    dtype='float32',\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(MaxPooling1D(data_format= 'channels_last',\n",
        "    dtype= 'float32',\n",
        "    padding='valid',\n",
        "    pool_size=(9,),\n",
        "    strides= (3,),\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(Dropout(dtype= 'float32',\n",
        "    noise_shape= None,\n",
        "    rate= 0.2,\n",
        "    seed= None,\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(Conv1D(activation= 'relu',\n",
        "    activity_regularizer= None,\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer= None,\n",
        "    data_format= 'channels_last',\n",
        "    dilation_rate= (1,),\n",
        "    dtype= 'float32',\n",
        "    filters= 480,\n",
        "    groups= 1,\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 0.9}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
        "    kernel_size= (4,),\n",
        "    padding= 'valid',\n",
        "    strides= (1,),\n",
        "    trainable= True,\n",
        "    use_bias= True))\n",
        "\n",
        "model1.add(BatchNormalization(beta_constraint= None,\n",
        "    beta_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    beta_regularizer= None,\n",
        "    center= True,\n",
        "    dtype= 'float32',\n",
        "    epsilon= 0.001,\n",
        "    gamma_constraint= None,\n",
        "    gamma_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    gamma_regularizer= None,\n",
        "    momentum= 0.99,\n",
        "    moving_mean_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    moving_variance_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    scale= True,\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(LeakyReLU(alpha= 0.0,\n",
        "    dtype='float32',\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(MaxPooling1D(data_format='channels_last',\n",
        "    dtype='float32',\n",
        "    padding='valid',\n",
        "    pool_size= (4,),\n",
        "    strides=(2,),\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(Dropout(dtype= 'float32',\n",
        "    noise_shape= None,\n",
        "    rate= 0.2,\n",
        "    seed= None,\n",
        "    trainable= True))\n",
        "\n",
        "##\n",
        "model1.add(Conv1D(activation= 'relu',\n",
        "    activity_regularizer= None,\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer= None,\n",
        "    data_format= 'channels_last',\n",
        "    dilation_rate= (1,),\n",
        "    dtype= 'float32',\n",
        "    filters= 240,\n",
        "    groups= 1,\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
        "    kernel_size= (4,),\n",
        "    padding= 'valid',\n",
        "    strides= (1,),\n",
        "    trainable= True,\n",
        "    use_bias= True))\n",
        "\n",
        "\n",
        "model1.add(MaxPooling1D(data_format='channels_last',\n",
        "    dtype='float32',\n",
        "    padding='valid',\n",
        "    pool_size= (4,),\n",
        "    strides=(3,),\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(Dropout(dtype= 'float32',\n",
        "    noise_shape= None,\n",
        "    rate= 0.2,\n",
        "    seed= None,\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(Conv1D(activation= 'relu',\n",
        "    activity_regularizer= None,\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer= None,\n",
        "    data_format= 'channels_last',\n",
        "    dilation_rate= (1,),\n",
        "    dtype= 'float32',\n",
        "    filters= 320,\n",
        "    groups= 1,\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
        "    kernel_size= (1,),\n",
        "    padding= 'valid',\n",
        "    strides= (1,),\n",
        "    trainable= True,\n",
        "    use_bias= True))\n",
        "\n",
        "model1.add(BatchNormalization(beta_constraint= None,\n",
        "    beta_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    beta_regularizer= None,\n",
        "    center= True,\n",
        "    dtype= 'float32',\n",
        "    epsilon= 0.001,\n",
        "    gamma_constraint= None,\n",
        "    gamma_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    gamma_regularizer= None,\n",
        "    momentum= 0.99,\n",
        "    moving_mean_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    moving_variance_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    scale= True,\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(LeakyReLU(alpha= 0.0,dtype='float32',trainable=True))\n",
        "\n",
        "model1.add(MaxPooling1D(data_format='channels_last',\n",
        "    dtype='float32',\n",
        "    padding='valid',\n",
        "    pool_size= (1,),\n",
        "    strides=(3,),\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(Flatten(data_format= 'channels_last',\n",
        "    dtype= 'float32',\n",
        "  trainable= True))\n",
        "\n",
        "model1.add(Dense(180,activation='sigmoid', activity_regularizer=None,\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer=None,\n",
        "    dtype='float32',\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer={'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}}, \n",
        "     trainable=True,\t\n",
        "    use_bias= True\n",
        "     ))\n",
        "\n",
        "model1.add(Dense(2,activation='softmax',activity_regularizer= None,bias_constraint= None,\n",
        "                 kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}}\n",
        "     ))\n",
        "\n",
        "model1.build()"
      ],
      "metadata": {
        "id": "umZ3q-2R38di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "31rs43u238dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXlD_DvEdklE",
        "outputId": "ed79f837-8dd7-4341-93c6-5ac9ecc53919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 200, 4),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'input_1',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 200, 4),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (9,),\n",
              "    'name': 'conv1d',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (9,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 0.9}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_1',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_1',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_1',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_1',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (2,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_1',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 240,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_2',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_2',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_2',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 320,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (1,),\n",
              "    'name': 'conv1d_3',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_2',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_2',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_3',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (1,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Flatten',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'flatten',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'sigmoid',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense',\n",
              "    'trainable': True,\n",
              "    'units': 180,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'softmax',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense_1',\n",
              "    'trainable': True,\n",
              "    'units': 2,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential_1'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary(expand_nested=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWHceg6zc6aQ",
        "outputId": "c9bbbfb5-25b8-489a-f01f-38190a022e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 192, 480)          17760     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 192, 480)         1920      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 192, 480)          0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 62, 480)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 62, 480)           0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 59, 480)           922080    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 59, 480)          1920      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 59, 480)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 28, 480)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 28, 480)           0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 25, 240)           461040    \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 8, 240)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 240)            0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 8, 320)            77120     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 320)           1280      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 320)            0         \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 3, 320)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 960)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 180)               172980    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 362       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,656,462\n",
            "Trainable params: 1,653,902\n",
            "Non-trainable params: 2,560\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(Dfile):\n",
        "\n",
        "    print(\"reading enhancers...\")\n",
        "    data = {}\n",
        "    with h5py.File(Dfile, \"r\") as inf:\n",
        "        for _key in inf:\n",
        "            data[_key] = inf[_key][()]\n",
        "    return data"
      ],
      "metadata": {
        "id": "B_7PwyyCouX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mo2mQzO-pZPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip -d /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5.gz"
      ],
      "metadata": {
        "id": "KVAanGsOpgvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset('/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5')"
      ],
      "metadata": {
        "id": "qwqHKgXRo8qE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d012b9cf-af76-49c5-9175-fdd4caeafe12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading enhancers...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data[\"train_data\"]\n",
        "Y_train = data[\"train_labels\"]\n",
        "X_validation = data[\"val_data\"]\n",
        "Y_validation = data[\"val_labels\"]\n",
        "X_test = data[\"test_data\"]\n",
        "Y_test = data[\"test_labels\"]"
      ],
      "metadata": {
        "id": "xZM2J-wBpFNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_model = model1"
      ],
      "metadata": {
        "id": "rO_OrLseotbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "'''\n",
        "Y_train = to_categorical(Y_train, num_classes=None)\n",
        "Y_test = to_categorical(Y_test, num_classes=None)\n",
        "Y_validation = to_categorical(Y_validation, num_classes=None)\n",
        "'''\n",
        "\n",
        "\n",
        "_callbacks = []\n",
        "checkpointer = ModelCheckpoint(filepath=weights_file, verbose=1, save_best_only=True)\n",
        "_callbacks.append(checkpointer)\n",
        "earlystopper = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)\n",
        "_callbacks.append(earlystopper)"
      ],
      "metadata": {
        "id": "LPKGM60CouUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OUR MODEL"
      ],
      "metadata": {
        "id": "jv_q9IA795pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_model.fit(X_train,\n",
        "                    Y_train,\n",
        "                    batch_size=BATCH_SIZE * 1,\n",
        "                    epochs=EPOCH,\n",
        "                    validation_data=(X_validation, Y_validation),\n",
        "                    shuffle=True,\n",
        "                    callbacks=_callbacks, verbose=1)\n",
        "\n",
        "Y_pred = parallel_model.predict(X_test)"
      ],
      "metadata": {
        "id": "FsoVn3nLuwDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "547af51c-c822-4786-e0ac-f2bbda671295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.7081 - accuracy: 0.5484\n",
            "Epoch 1: val_loss improved from inf to 0.79110, saving model to ./examples/model_weights.hdf5\n",
            "78/78 [==============================] - 18s 69ms/step - loss: 0.7081 - accuracy: 0.5484 - val_loss: 0.7911 - val_accuracy: 0.5045\n",
            "Epoch 2/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.5927\n",
            "Epoch 2: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6775 - accuracy: 0.5921 - val_loss: 0.8873 - val_accuracy: 0.5045\n",
            "Epoch 3/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6594 - accuracy: 0.6201\n",
            "Epoch 3: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6597 - accuracy: 0.6196 - val_loss: 0.9653 - val_accuracy: 0.5045\n",
            "Epoch 4/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6385 - accuracy: 0.6406\n",
            "Epoch 4: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6386 - accuracy: 0.6400 - val_loss: 1.0733 - val_accuracy: 0.5045\n",
            "Epoch 5/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6275 - accuracy: 0.6554\n",
            "Epoch 5: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6277 - accuracy: 0.6551 - val_loss: 1.1260 - val_accuracy: 0.5045\n",
            "Epoch 6/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6003 - accuracy: 0.6776\n",
            "Epoch 6: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.6003 - accuracy: 0.6774 - val_loss: 1.2426 - val_accuracy: 0.5045\n",
            "Epoch 7/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.5720 - accuracy: 0.7058\n",
            "Epoch 7: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5730 - accuracy: 0.7049 - val_loss: 1.4309 - val_accuracy: 0.5045\n",
            "Epoch 8/200\n",
            "15/78 [====>.........................] - ETA: 3s - loss: 0.5113 - accuracy: 0.7677"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('/content/SilencerEnhancerPredict/examples/model.hdf5')"
      ],
      "metadata": {
        "id": "Nc21tubB38dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! gunzip /content/SilencerEnhancerPredict/examples/model.hdf5.gz"
      ],
      "metadata": {
        "id": "rxZxlO-OF6i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "history = model1.fit(input_train, target_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=no_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split)\n",
        "          '''"
      ],
      "metadata": {
        "id": "uqmDJQ4Ivy9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "88df4c48-dd06-4e21-f41a-05f3d3f8ba9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhistory = model1.fit(input_train, target_train,\\n          batch_size=batch_size,\\n          epochs=no_epochs,\\n          verbose=verbosity,\\n          validation_split=validation_split)\\n          '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "# To get learning rate\n",
        "print(K.get_value(model1.optimizer.lr))"
      ],
      "metadata": {
        "id": "O3RjK8Zkm5MK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986dc133-9c46-487c-a7f9-0edf27446390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "xEdYusifkHfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gunzip /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5"
      ],
      "metadata": {
        "id": "gtMkJ25yaXBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install Bio\n",
        "%pip install pybedtools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dgZ8wc1nrz5",
        "outputId": "a2c262d0-3585-4afe-df6f-acdad287fa53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Bio\n",
            "  Downloading bio-1.3.8-py3-none-any.whl (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Bio) (4.63.0)\n",
            "Collecting biopython>=1.79\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 41.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Bio) (2.23.0)\n",
            "Collecting mygene\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->Bio) (1.21.5)\n",
            "Collecting biothings-client>=0.2.6\n",
            "  Downloading biothings_client-0.2.6-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (3.0.4)\n",
            "Installing collected packages: biothings-client, mygene, biopython, Bio\n",
            "Successfully installed Bio-1.3.8 biopython-1.79 biothings-client-0.2.6 mygene-3.2.2\n",
            "Collecting pybedtools\n",
            "  Downloading pybedtools-0.9.0.tar.gz (12.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pybedtools) (1.15.0)\n",
            "Collecting pysam\n",
            "  Downloading pysam-0.19.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.0 MB 18.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pybedtools\n",
            "  Building wheel for pybedtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybedtools: filename=pybedtools-0.9.0-cp37-cp37m-linux_x86_64.whl size=13616823 sha256=693ec8b30e24f7ea68bcba038b76ffaa20aa455a69be56db3073cc54d1a934fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/44/0d/3a7449885adaf8ebb157da8c3c834a712f48b3b3b84ba51dda\n",
            "Successfully built pybedtools\n",
            "Installing collected packages: pysam, pybedtools\n",
            "Successfully installed pybedtools-0.9.0 pysam-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SilencerEnhancerPredict/train.py /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5 /content/SilencerEnhancerPredict/examples/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-0r7UqYnObh",
        "outputId": "b56db1d2-169e-497a-c641-c803242a48b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-13 15:44:48.770559: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "reading enhancers...\n",
            "Epoch 1/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.5218 - accuracy: 0.7807\n",
            "Epoch 1: val_loss improved from inf to 0.50572, saving model to /content/SilencerEnhancerPredict/examples/model_weights.hdf5\n",
            "78/78 [==============================] - 24s 63ms/step - loss: 0.5218 - accuracy: 0.7807 - val_loss: 0.5057 - val_accuracy: 0.7805\n",
            "Epoch 2/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8405\n",
            "Epoch 2: val_loss improved from 0.50572 to 0.48107, saving model to /content/SilencerEnhancerPredict/examples/model_weights.hdf5\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.3777 - accuracy: 0.8405 - val_loss: 0.4811 - val_accuracy: 0.7993\n",
            "Epoch 3/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.8768\n",
            "Epoch 3: val_loss did not improve from 0.48107\n",
            "78/78 [==============================] - 5s 65ms/step - loss: 0.3103 - accuracy: 0.8773 - val_loss: 0.6272 - val_accuracy: 0.7326\n",
            "Epoch 4/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.2481 - accuracy: 0.9030\n",
            "Epoch 4: val_loss did not improve from 0.48107\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.2477 - accuracy: 0.9030 - val_loss: 0.8216 - val_accuracy: 0.6865\n",
            "Epoch 5/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.2117 - accuracy: 0.9172\n",
            "Epoch 5: val_loss did not improve from 0.48107\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.2123 - accuracy: 0.9169 - val_loss: 0.6928 - val_accuracy: 0.7229\n",
            "Epoch 6/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.9258\n",
            "Epoch 6: val_loss did not improve from 0.48107\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1912 - accuracy: 0.9258 - val_loss: 1.1210 - val_accuracy: 0.5719\n",
            "Epoch 7/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9387\n",
            "Epoch 7: val_loss did not improve from 0.48107\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1622 - accuracy: 0.9388 - val_loss: 1.0634 - val_accuracy: 0.6525\n",
            "Epoch 8/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9468\n",
            "Epoch 8: val_loss did not improve from 0.48107\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1461 - accuracy: 0.9468 - val_loss: 0.9578 - val_accuracy: 0.6659\n",
            "Epoch 9/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.1446 - accuracy: 0.9448\n",
            "Epoch 9: val_loss did not improve from 0.48107\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1448 - accuracy: 0.9446 - val_loss: 0.8757 - val_accuracy: 0.6986\n",
            "Epoch 10/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9553\n",
            "Epoch 10: val_loss did not improve from 0.48107\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1221 - accuracy: 0.9553 - val_loss: 0.9904 - val_accuracy: 0.7029\n",
            "Epoch 11/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.9594\n",
            "Epoch 11: val_loss did not improve from 0.48107\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1070 - accuracy: 0.9592 - val_loss: 1.3614 - val_accuracy: 0.6458\n",
            "Epoch 12/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9610\n",
            "Epoch 12: val_loss did not improve from 0.48107\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1119 - accuracy: 0.9610 - val_loss: 1.0389 - val_accuracy: 0.6925\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SilencerEnhancerPredict/predict.py /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5 /content/SilencerEnhancerPredict/examples/model_weights.hdf5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_gGYsRKnmP7",
        "outputId": "01fcc8a8-d02f-4452-f539-581d1913d4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-13 15:46:09.350446: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "reading samples...\n",
            "prediction on test samples ...\n",
            "9/9 [==============================] - 2s 54ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# reading from the file\n",
        "path=\"/content/SilencerEnhancerPredict/examples/data_prediction.hdf5.pred.data\"\n",
        "with open(path, 'rb') as f:\n",
        "  contents = f.read()\n",
        "contents\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "94rQ49Pcu3cs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "146d59dc-c205-435a-b990-08ddd5ef33f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# reading from the file\\npath=\"/content/SilencerEnhancerPredict/examples/data_prediction.hdf5.pred.data\"\\nwith open(path, \\'rb\\') as f:\\n  contents = f.read()\\ncontents\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import h5py\n",
        "filename = \"/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5\"\n",
        "\n",
        "with h5py.File(filename, \"r\") as f:\n",
        "    # List all groups\n",
        "    print(\"Keys: %s\" % f.keys())\n",
        "    a_group_key = list(f.keys())[0]\n",
        "\n",
        "    # Get the data\n",
        "    data = list(f[a_group_key])\n",
        "    #print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEJ_Q9LPcsaB",
        "outputId": "c6cc08a9-48b0-40f3-ced8-687f18dfec1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: <KeysViewHDF5 ['test_data', 'test_labels', 'train_data', 'train_labels', 'val_data', 'val_labels']>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "id": "0IkUDiXJankE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c810f8-881f-471d-b705-702ab965d78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "bYt4hI59awVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913fbcbd-e730-4eb7-9947-e927c01520a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1650"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0])"
      ],
      "metadata": {
        "id": "gX1EDAagayKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c523642a-9ad9-4503-e600-fa37b9218c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUIfhzY9a0mS",
        "outputId": "dfa679ab-a243-44c2-a993-077bc99dd0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f= '/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5.pred.data'"
      ],
      "metadata": {
        "id": "bxTAzFKXNlO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "with h5py.File(f, \"r\") as f:\n",
        "    # List all groups\n",
        "    print(\"Keys: %s\" % f.keys())\n",
        "    a_group_key = list(f.keys())[0]\n",
        "\n",
        "    # Get the data\n",
        "    data_pred = list(f[a_group_key])\n",
        "    #print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfoLXAJNP5mI",
        "outputId": "876c9c17-e73b-4ea9-b178-3511a8615b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: <KeysViewHDF5 ['ypred']>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data_pred))"
      ],
      "metadata": {
        "id": "Wm_HIPwkjbQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6febf6c-590c-446c-dbc1-2989297eaf5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtLnpMqKk8MT",
        "outputId": "e9d81869-dc05-46b3-eeb1-31c819e0a40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.8387063 , 0.16129364], dtype=float32),\n",
              " array([0.13233241, 0.86766756], dtype=float32),\n",
              " array([0.02656471, 0.9734353 ], dtype=float32),\n",
              " array([0.34341872, 0.6565813 ], dtype=float32),\n",
              " array([0.7533496 , 0.24665046], dtype=float32),\n",
              " array([0.1877739, 0.8122261], dtype=float32),\n",
              " array([0.00799239, 0.9920076 ], dtype=float32),\n",
              " array([0.65625805, 0.34374195], dtype=float32),\n",
              " array([0.1009581 , 0.89904195], dtype=float32),\n",
              " array([0.0761948 , 0.92380524], dtype=float32),\n",
              " array([0.16273876, 0.8372612 ], dtype=float32),\n",
              " array([0.3295057, 0.6704943], dtype=float32),\n",
              " array([0.01670506, 0.9832949 ], dtype=float32),\n",
              " array([0.63412005, 0.36587995], dtype=float32),\n",
              " array([0.87882775, 0.1211722 ], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkRCiyorosyn",
        "outputId": "6a9607dd-c700-4228-c7ed-881ea36bf34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8387063"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_pred[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-S5G2ialFB3",
        "outputId": "1f12193b-8e6b-4536-e9d4-4d8fb52c8572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "01 - class 1 - tad \n",
        "\n",
        "10 - class 0 - left \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fa4AYevFoDRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred_class = []\n",
        "for i in range(len(data_pred)):\n",
        "  if data_pred[i][0] > data_pred[i][1]:\n",
        "    data_pred_class.append(0) #left\n",
        "  else: \n",
        "    data_pred_class.append(1) #right\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "X1fzbbVLoG6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DepBgHXqBdz",
        "outputId": "fc57a8b1-afb2-4e99-f1e0-6ef38d2e2643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1650"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-7QVqULpKhg",
        "outputId": "ad17a1e5-c673-4678-d345-0091ce8c556e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d1,d2 = [],[]\n",
        "with h5py.File('/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5', 'r') as f:\n",
        "    d1 = f['test_data'][:].tolist()\n",
        "    d2 = f['test_labels'][:].tolist()\n",
        "   "
      ],
      "metadata": {
        "id": "6fZ38NZ3oAtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(d2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38JU-T25pi74",
        "outputId": "692a7a6b-9392-4386-bab9-29e1b2d7e704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2[0] == [1.0, 0.0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOTeCDdepq8g",
        "outputId": "dd5415bb-0702-4f9f-e882-2ae758533941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_orig_class = []\n",
        "for i in range(len(d2)):\n",
        "  if(d2[i] == [1.0, 0.0]):\n",
        "    data_orig_class.append(0)\n",
        "  else:\n",
        "    data_orig_class.append(1)\n"
      ],
      "metadata": {
        "id": "mRfU3oZCpnM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_orig_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2giXj4EpdHH",
        "outputId": "9abccb90-29ff-41fc-bc3f-1d3803208552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy \n",
        "import sklearn.metrics\n",
        "sklearn.metrics.accuracy_score(data_orig_class, data_pred_class, normalize=True, sample_weight=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGW3jEvAp-xv",
        "outputId": "730083f3-81fc-4dea-f2eb-56c0ba963670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7818181818181819"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "fpr , tpr , thresholds = roc_curve (data_orig_class, data_pred_class)\n",
        "\n",
        "def plot_roc_curve(fpr,tpr): \n",
        "  plt.plot(fpr,tpr) \n",
        "  plt.axis([0,1,0,1]) \n",
        "  plt.xlabel('False Positive Rate') \n",
        "  plt.ylabel('True Positive Rate') \n",
        "  plt.show()    \n",
        "  \n",
        "plot_roc_curve (fpr,tpr) "
      ],
      "metadata": {
        "id": "zFgIH-toqHzJ",
        "outputId": "e4578b08-0670-4ff9-8443-d5cb9683dc77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W1QvTQy1mw0E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}