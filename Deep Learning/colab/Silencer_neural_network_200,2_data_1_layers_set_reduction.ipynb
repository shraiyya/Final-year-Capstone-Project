{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Silencer neural network- 200,2 data - 1 layers set reduction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radhikasethi2011/SilencerEnhancerPredict/blob/main/colab/Silencer_neural_network_200%2C2_data_1_layers_set_reduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/radhikasethi2011/SilencerEnhancerPredict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsGdEyz9ej92",
        "outputId": "2b362081-96f9-4b99-c71d-c46013f2aa3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SilencerEnhancerPredict'...\n",
            "remote: Enumerating objects: 284, done.\u001b[K\n",
            "remote: Counting objects: 100% (284/284), done.\u001b[K\n",
            "remote: Compressing objects: 100% (248/248), done.\u001b[K\n",
            "remote: Total 284 (delta 134), reused 68 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (284/284), 151.03 MiB | 16.96 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n",
            "Checking out files: 100% (54/54), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/SilencerEnhancerPredict/examples/"
      ],
      "metadata": {
        "id": "iulfH4gnhoxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4458d871-4f38-4b31-d847-446784ef894c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SilencerEnhancerPredict/examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from sklearn import metrics\n",
        "import h5py\n",
        "import os"
      ],
      "metadata": {
        "id": "SCMSlHzvoM7o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_LENGTH = 200\n",
        "EPOCH = 200\n",
        "BATCH_SIZE = 64\n",
        "WORK_DIR = \"./\""
      ],
      "metadata": {
        "id": "909G7HHhqf0B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------\n"
      ],
      "metadata": {
        "id": "Apk8No7Sj-Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('model.hdf5')"
      ],
      "metadata": {
        "id": "-zQSwuaJh4il"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYNvJsv7leZ_",
        "outputId": "32f0656e-1141-4409-a80f-e88cdd23902b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 992, 480)          17760     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 992, 480)         1920      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 992, 480)          0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 328, 480)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 328, 480)          0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 325, 480)          922080    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 325, 480)         1920      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 325, 480)          0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 161, 480)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 161, 480)          0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 158, 240)          461040    \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 52, 240)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 52, 240)           0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 49, 320)           307520    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 49, 320)          1280      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 49, 320)           0         \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 16, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 13, 320)           409920    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 13, 320)          1280      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 13, 320)           0         \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 4, 320)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 180)               230580    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 543       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,355,843\n",
            "Trainable params: 2,352,643\n",
            "Non-trainable params: 3,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqk45uRWaH0k",
        "outputId": "4114d8a7-ad5c-442a-8b6d-6dbfa5d18a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 1000, 4),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'conv1d_1_input',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 1000, 4),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (9,),\n",
              "    'name': 'conv1d_1',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_1',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_1',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_1',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (9,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_1',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 0.9}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_2',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_2',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_2',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_2',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (2,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_2',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 240,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_3',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_3',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_3',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 320,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_4',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_3',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_3',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_4',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 320,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_5',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_4',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_4',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_5',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Flatten',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'flatten_1',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'sigmoid',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense_1',\n",
              "    'trainable': True,\n",
              "    'units': 180,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'softmax',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense_2',\n",
              "    'trainable': True,\n",
              "    'units': 3,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_file = os.path.join('./examples', \"model_weights.hdf5\")\n",
        "model_file = os.path.join('./examples', \"single_model.hdf5\")\n",
        "model.save(model_file)"
      ],
      "metadata": {
        "id": "VQEkjHcMqAVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afb074b-86d8-4aba-cf90-668631ae7f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_config"
      ],
      "metadata": {
        "id": "tg3r-08QGljQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d66163-9f61-4895-c3a3-dcba4aa9a877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Sequential.get_config of <keras.engine.sequential.Sequential object at 0x7f0f15ba9ed0>>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adadelta()"
      ],
      "metadata": {
        "id": "gsHsFed5op0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODE BASED ON PAPER:"
      ],
      "metadata": {
        "id": "3fA5aQAN38dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import InputLayer, LeakyReLU\n",
        "\n",
        "model1 = Sequential(InputLayer(batch_input_shape= (None, 200, 4),\n",
        "    dtype= 'float32',\n",
        "    ragged= False,\n",
        "    sparse= False))\n",
        "\n",
        "model1.add(Conv1D(activation= 'relu',\n",
        "    activity_regularizer= None,\n",
        "    batch_input_shape= (None, 200, 4),\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer= None,\n",
        "    data_format= 'channels_last',\n",
        "    dilation_rate= (1,),\n",
        "    dtype= 'float32',\n",
        "    filters= 480,\n",
        "    groups= 1,\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
        "    kernel_size= (9,),\n",
        "    padding= 'valid',\n",
        "    strides= (1,),\n",
        "    trainable= True,\n",
        "    use_bias= True))\n",
        "\n",
        "model1.add(BatchNormalization(\n",
        "    beta_constraint= None,\n",
        "    beta_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    beta_regularizer= None,\n",
        "    center= True,\n",
        "    dtype= 'float32',\n",
        "    epsilon= 0.001,\n",
        "    gamma_constraint= None,\n",
        "    gamma_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    gamma_regularizer= None,\n",
        "    momentum= 0.99,\n",
        "    moving_mean_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    moving_variance_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    scale= True,\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(LeakyReLU(alpha= 0.0,\n",
        "    dtype='float32',\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(MaxPooling1D(data_format= 'channels_last',\n",
        "    dtype= 'float32',\n",
        "    padding='valid',\n",
        "    pool_size=(9,),\n",
        "    strides= (3,),\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(Dropout(dtype= 'float32',\n",
        "    noise_shape= None,\n",
        "    rate= 0.2,\n",
        "    seed= None,\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(Conv1D(activation= 'relu',\n",
        "    activity_regularizer= None,\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer= None,\n",
        "    data_format= 'channels_last',\n",
        "    dilation_rate= (1,),\n",
        "    dtype= 'float32',\n",
        "    filters= 480,\n",
        "    groups= 1,\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 0.9}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
        "    kernel_size= (4,),\n",
        "    padding= 'valid',\n",
        "    strides= (1,),\n",
        "    trainable= True,\n",
        "    use_bias= True))\n",
        "\n",
        "model1.add(BatchNormalization(beta_constraint= None,\n",
        "    beta_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    beta_regularizer= None,\n",
        "    center= True,\n",
        "    dtype= 'float32',\n",
        "    epsilon= 0.001,\n",
        "    gamma_constraint= None,\n",
        "    gamma_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    gamma_regularizer= None,\n",
        "    momentum= 0.99,\n",
        "    moving_mean_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    moving_variance_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    scale= True,\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(LeakyReLU(alpha= 0.0,\n",
        "    dtype='float32',\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(MaxPooling1D(data_format='channels_last',\n",
        "    dtype='float32',\n",
        "    padding='valid',\n",
        "    pool_size= (4,),\n",
        "    strides=(2,),\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(Dropout(dtype= 'float32',\n",
        "    noise_shape= None,\n",
        "    rate= 0.2,\n",
        "    seed= None,\n",
        "    trainable= True))\n",
        "\n",
        "##\n",
        "model1.add(Conv1D(activation= 'relu',\n",
        "    activity_regularizer= None,\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer= None,\n",
        "    data_format= 'channels_last',\n",
        "    dilation_rate= (1,),\n",
        "    dtype= 'float32',\n",
        "    filters= 240,\n",
        "    groups= 1,\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
        "    kernel_size= (4,),\n",
        "    padding= 'valid',\n",
        "    strides= (1,),\n",
        "    trainable= True,\n",
        "    use_bias= True))\n",
        "\n",
        "\n",
        "model1.add(MaxPooling1D(data_format='channels_last',\n",
        "    dtype='float32',\n",
        "    padding='valid',\n",
        "    pool_size= (4,),\n",
        "    strides=(3,),\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(Dropout(dtype= 'float32',\n",
        "    noise_shape= None,\n",
        "    rate= 0.2,\n",
        "    seed= None,\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(Conv1D(activation= 'relu',\n",
        "    activity_regularizer= None,\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer= None,\n",
        "    data_format= 'channels_last',\n",
        "    dilation_rate= (1,),\n",
        "    dtype= 'float32',\n",
        "    filters= 320,\n",
        "    groups= 1,\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
        "    kernel_size= (1,),\n",
        "    padding= 'valid',\n",
        "    strides= (1,),\n",
        "    trainable= True,\n",
        "    use_bias= True))\n",
        "\n",
        "model1.add(BatchNormalization(beta_constraint= None,\n",
        "    beta_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    beta_regularizer= None,\n",
        "    center= True,\n",
        "    dtype= 'float32',\n",
        "    epsilon= 0.001,\n",
        "    gamma_constraint= None,\n",
        "    gamma_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    gamma_regularizer= None,\n",
        "    momentum= 0.99,\n",
        "    moving_mean_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    moving_variance_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    scale= True,\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(LeakyReLU(alpha= 0.0,dtype='float32',trainable=True))\n",
        "\n",
        "model1.add(MaxPooling1D(data_format='channels_last',\n",
        "    dtype='float32',\n",
        "    padding='valid',\n",
        "    pool_size= (1,),\n",
        "    strides=(3,),\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(Flatten(data_format= 'channels_last',\n",
        "    dtype= 'float32',\n",
        "  trainable= True))\n",
        "\n",
        "model1.add(Dense(180,activation='sigmoid', activity_regularizer=None,\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer=None,\n",
        "    dtype='float32',\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer={'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}}, \n",
        "     trainable=True,\t\n",
        "    use_bias= True\n",
        "     ))\n",
        "\n",
        "model1.add(Dense(2,activation='softmax',activity_regularizer= None,bias_constraint= None,\n",
        "                 kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}}\n",
        "     ))\n",
        "\n",
        "model1.build()"
      ],
      "metadata": {
        "id": "umZ3q-2R38di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "31rs43u238dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXlD_DvEdklE",
        "outputId": "ed79f837-8dd7-4341-93c6-5ac9ecc53919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 200, 4),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'input_1',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 200, 4),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (9,),\n",
              "    'name': 'conv1d',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (9,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 0.9}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_1',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_1',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_1',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_1',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (2,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_1',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 240,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_2',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_2',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_2',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 320,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (1,),\n",
              "    'name': 'conv1d_3',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_2',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_2',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_3',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (1,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Flatten',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'flatten',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'sigmoid',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense',\n",
              "    'trainable': True,\n",
              "    'units': 180,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'softmax',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense_1',\n",
              "    'trainable': True,\n",
              "    'units': 2,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential_1'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary(expand_nested=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWHceg6zc6aQ",
        "outputId": "c9bbbfb5-25b8-489a-f01f-38190a022e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 192, 480)          17760     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 192, 480)         1920      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 192, 480)          0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 62, 480)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 62, 480)           0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 59, 480)           922080    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 59, 480)          1920      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 59, 480)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 28, 480)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 28, 480)           0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 25, 240)           461040    \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 8, 240)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 240)            0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 8, 320)            77120     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 320)           1280      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 320)            0         \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 3, 320)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 960)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 180)               172980    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 362       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,656,462\n",
            "Trainable params: 1,653,902\n",
            "Non-trainable params: 2,560\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(Dfile):\n",
        "\n",
        "    print(\"reading enhancers...\")\n",
        "    data = {}\n",
        "    with h5py.File(Dfile, \"r\") as inf:\n",
        "        for _key in inf:\n",
        "            data[_key] = inf[_key][()]\n",
        "    return data"
      ],
      "metadata": {
        "id": "B_7PwyyCouX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mo2mQzO-pZPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip -d /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5.gz"
      ],
      "metadata": {
        "id": "KVAanGsOpgvu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset('/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5')"
      ],
      "metadata": {
        "id": "qwqHKgXRo8qE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d012b9cf-af76-49c5-9175-fdd4caeafe12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading enhancers...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data[\"train_data\"]\n",
        "Y_train = data[\"train_labels\"]\n",
        "X_validation = data[\"val_data\"]\n",
        "Y_validation = data[\"val_labels\"]\n",
        "X_test = data[\"test_data\"]\n",
        "Y_test = data[\"test_labels\"]"
      ],
      "metadata": {
        "id": "xZM2J-wBpFNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_model = model1"
      ],
      "metadata": {
        "id": "rO_OrLseotbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "'''\n",
        "Y_train = to_categorical(Y_train, num_classes=None)\n",
        "Y_test = to_categorical(Y_test, num_classes=None)\n",
        "Y_validation = to_categorical(Y_validation, num_classes=None)\n",
        "'''\n",
        "\n",
        "\n",
        "_callbacks = []\n",
        "checkpointer = ModelCheckpoint(filepath=weights_file, verbose=1, save_best_only=True)\n",
        "_callbacks.append(checkpointer)\n",
        "earlystopper = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)\n",
        "_callbacks.append(earlystopper)"
      ],
      "metadata": {
        "id": "LPKGM60CouUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OUR MODEL"
      ],
      "metadata": {
        "id": "jv_q9IA795pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_model.fit(X_train,\n",
        "                    Y_train,\n",
        "                    batch_size=BATCH_SIZE * 1,\n",
        "                    epochs=EPOCH,\n",
        "                    validation_data=(X_validation, Y_validation),\n",
        "                    shuffle=True,\n",
        "                    callbacks=_callbacks, verbose=1)\n",
        "\n",
        "Y_pred = parallel_model.predict(X_test)"
      ],
      "metadata": {
        "id": "FsoVn3nLuwDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "547af51c-c822-4786-e0ac-f2bbda671295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.7081 - accuracy: 0.5484\n",
            "Epoch 1: val_loss improved from inf to 0.79110, saving model to ./examples/model_weights.hdf5\n",
            "78/78 [==============================] - 18s 69ms/step - loss: 0.7081 - accuracy: 0.5484 - val_loss: 0.7911 - val_accuracy: 0.5045\n",
            "Epoch 2/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.5927\n",
            "Epoch 2: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6775 - accuracy: 0.5921 - val_loss: 0.8873 - val_accuracy: 0.5045\n",
            "Epoch 3/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6594 - accuracy: 0.6201\n",
            "Epoch 3: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6597 - accuracy: 0.6196 - val_loss: 0.9653 - val_accuracy: 0.5045\n",
            "Epoch 4/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6385 - accuracy: 0.6406\n",
            "Epoch 4: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6386 - accuracy: 0.6400 - val_loss: 1.0733 - val_accuracy: 0.5045\n",
            "Epoch 5/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6275 - accuracy: 0.6554\n",
            "Epoch 5: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6277 - accuracy: 0.6551 - val_loss: 1.1260 - val_accuracy: 0.5045\n",
            "Epoch 6/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6003 - accuracy: 0.6776\n",
            "Epoch 6: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.6003 - accuracy: 0.6774 - val_loss: 1.2426 - val_accuracy: 0.5045\n",
            "Epoch 7/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.5720 - accuracy: 0.7058\n",
            "Epoch 7: val_loss did not improve from 0.79110\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5730 - accuracy: 0.7049 - val_loss: 1.4309 - val_accuracy: 0.5045\n",
            "Epoch 8/200\n",
            "15/78 [====>.........................] - ETA: 3s - loss: 0.5113 - accuracy: 0.7677"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('/content/SilencerEnhancerPredict/examples/model.hdf5')"
      ],
      "metadata": {
        "id": "Nc21tubB38dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! gunzip /content/SilencerEnhancerPredict/examples/model.hdf5.gz"
      ],
      "metadata": {
        "id": "rxZxlO-OF6i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "history = model1.fit(input_train, target_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=no_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split)\n",
        "          '''"
      ],
      "metadata": {
        "id": "uqmDJQ4Ivy9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "88df4c48-dd06-4e21-f41a-05f3d3f8ba9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhistory = model1.fit(input_train, target_train,\\n          batch_size=batch_size,\\n          epochs=no_epochs,\\n          verbose=verbosity,\\n          validation_split=validation_split)\\n          '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "# To get learning rate\n",
        "print(K.get_value(model1.optimizer.lr))"
      ],
      "metadata": {
        "id": "O3RjK8Zkm5MK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986dc133-9c46-487c-a7f9-0edf27446390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "xEdYusifkHfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gunzip /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5"
      ],
      "metadata": {
        "id": "gtMkJ25yaXBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac94c24-1653-43eb-f3ce-d2f4460613fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5: unknown suffix -- ignored\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install Bio\n",
        "%pip install pybedtools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dgZ8wc1nrz5",
        "outputId": "64d30e6a-9fb3-4345-9c81-110ac1188b0f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Bio\n",
            "  Downloading bio-1.3.8-py3-none-any.whl (269 kB)\n",
            "\u001b[?25l\r\u001b[K     |                              | 10 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |                             | 20 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |                            | 30 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |                           | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |                          | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |                        | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |                       | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |                      | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |                     | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |                   | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |                  | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |                 | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |                | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |               | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |             | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |            | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |           | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |          | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |         | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |       | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |      | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |     | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |    | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |  | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     | | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     || 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     || 269 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Bio) (4.63.0)\n",
            "Collecting biopython>=1.79\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     || 2.3 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting mygene\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Bio) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->Bio) (1.21.5)\n",
            "Collecting biothings-client>=0.2.6\n",
            "  Downloading biothings_client-0.2.6-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2021.10.8)\n",
            "Installing collected packages: biothings-client, mygene, biopython, Bio\n",
            "Successfully installed Bio-1.3.8 biopython-1.79 biothings-client-0.2.6 mygene-3.2.2\n",
            "Collecting pybedtools\n",
            "  Downloading pybedtools-0.9.0.tar.gz (12.5 MB)\n",
            "\u001b[K     || 12.5 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pybedtools) (1.15.0)\n",
            "Collecting pysam\n",
            "  Downloading pysam-0.19.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.0 MB)\n",
            "\u001b[K     || 15.0 MB 17.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pybedtools\n",
            "  Building wheel for pybedtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybedtools: filename=pybedtools-0.9.0-cp37-cp37m-linux_x86_64.whl size=13616779 sha256=55d05533eaae2460f5eb4521363908c61d1cf4149e21e4d3f30ab2dc4ce5e301\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/44/0d/3a7449885adaf8ebb157da8c3c834a712f48b3b3b84ba51dda\n",
            "Successfully built pybedtools\n",
            "Installing collected packages: pysam, pybedtools\n",
            "Successfully installed pybedtools-0.9.0 pysam-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SilencerEnhancerPredict/train.py /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5 /content/SilencerEnhancerPredict/examples/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-0r7UqYnObh",
        "outputId": "bcbbe525-4f28-4f95-b4bd-0a443d5b736d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-12 07:03:59.443149: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "reading enhancers...\n",
            "Epoch 1/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9545\n",
            "Epoch 1: val_loss improved from inf to 1.52844, saving model to /content/SilencerEnhancerPredict/examples/model_weights.hdf5\n",
            "78/78 [==============================] - 9s 63ms/step - loss: 0.1250 - accuracy: 0.9545 - val_loss: 1.5284 - val_accuracy: 0.5646\n",
            "Epoch 2/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9606\n",
            "Epoch 2: val_loss did not improve from 1.52844\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1056 - accuracy: 0.9608 - val_loss: 1.6448 - val_accuracy: 0.5337\n",
            "Epoch 3/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9706\n",
            "Epoch 3: val_loss did not improve from 1.52844\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0863 - accuracy: 0.9705 - val_loss: 1.7312 - val_accuracy: 0.5622\n",
            "Epoch 4/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9671\n",
            "Epoch 4: val_loss did not improve from 1.52844\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0917 - accuracy: 0.9671 - val_loss: 1.6257 - val_accuracy: 0.5603\n",
            "Epoch 5/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.0974 - accuracy: 0.9657\n",
            "Epoch 5: val_loss did not improve from 1.52844\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0972 - accuracy: 0.9658 - val_loss: 1.5337 - val_accuracy: 0.5622\n",
            "Epoch 6/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9697\n",
            "Epoch 6: val_loss did not improve from 1.52844\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0830 - accuracy: 0.9697 - val_loss: 1.9457 - val_accuracy: 0.5233\n",
            "Epoch 7/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9693\n",
            "Epoch 7: val_loss did not improve from 1.52844\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0855 - accuracy: 0.9693 - val_loss: 1.6277 - val_accuracy: 0.5349\n",
            "Epoch 8/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9624\n",
            "Epoch 8: val_loss did not improve from 1.52844\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0979 - accuracy: 0.9624 - val_loss: 1.7606 - val_accuracy: 0.5591\n",
            "Epoch 9/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9658\n",
            "Epoch 9: val_loss did not improve from 1.52844\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0914 - accuracy: 0.9658 - val_loss: 2.6955 - val_accuracy: 0.5397\n",
            "Epoch 10/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9753\n",
            "Epoch 10: val_loss did not improve from 1.52844\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0659 - accuracy: 0.9753 - val_loss: 3.2520 - val_accuracy: 0.5264\n",
            "Epoch 11/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9737\n",
            "Epoch 11: val_loss did not improve from 1.52844\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0844 - accuracy: 0.9737 - val_loss: 1.9014 - val_accuracy: 0.5676\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SilencerEnhancerPredict/predict.py /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5 /content/SilencerEnhancerPredict/examples/model_weights.hdf5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_gGYsRKnmP7",
        "outputId": "b270d550-5934-41e2-af01-550ca4acf787"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-12 07:13:33.915740: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "reading samples...\n",
            "prediction on test samples ...\n",
            "9/9 [==============================] - 2s 47ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# reading from the file\n",
        "path=\"/content/SilencerEnhancerPredict/examples/data_prediction.hdf5.pred.data\"\n",
        "with open(path, 'rb') as f:\n",
        "  contents = f.read()\n",
        "contents\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "94rQ49Pcu3cs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7264ffbb-d8b2-4f49-85a6-5b5a75841ff1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# reading from the file\\npath=\"/content/SilencerEnhancerPredict/examples/data_prediction.hdf5.pred.data\"\\nwith open(path, \\'rb\\') as f:\\n  contents = f.read()\\ncontents\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import h5py\n",
        "filename = \"/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5\"\n",
        "\n",
        "with h5py.File(filename, \"r\") as f:\n",
        "    # List all groups\n",
        "    print(\"Keys: %s\" % f.keys())\n",
        "    a_group_key = list(f.keys())[0]\n",
        "\n",
        "    # Get the data\n",
        "    data = list(f[a_group_key])\n",
        "    #print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEJ_Q9LPcsaB",
        "outputId": "3fb63ea7-7dd0-4625-bd10-bd975061dd63"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: <KeysViewHDF5 ['test_data', 'test_labels', 'train_data', 'train_labels', 'val_data', 'val_labels']>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "id": "0IkUDiXJankE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d61407-cce8-4612-814a-d37ef4fd2e08"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "bYt4hI59awVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98efc20-3578-4f4b-daab-202311e22b87"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1650"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0])"
      ],
      "metadata": {
        "id": "gX1EDAagayKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a68755c-445e-43fb-d368-44bb70f440b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUIfhzY9a0mS",
        "outputId": "54cd5db3-798b-43b6-e18e-c2fbac203926"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f= '/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5.pred.data'"
      ],
      "metadata": {
        "id": "bxTAzFKXNlO8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "with h5py.File(f, \"r\") as f:\n",
        "    # List all groups\n",
        "    print(\"Keys: %s\" % f.keys())\n",
        "    a_group_key = list(f.keys())[0]\n",
        "\n",
        "    # Get the data\n",
        "    data_pred = list(f[a_group_key])\n",
        "    #print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfoLXAJNP5mI",
        "outputId": "9b502853-e79c-4d81-f30d-ca0c24cccb83"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: <KeysViewHDF5 ['ypred']>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data_pred))"
      ],
      "metadata": {
        "id": "Wm_HIPwkjbQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800a9d94-bb2f-460d-d00b-962ed8854dc0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtLnpMqKk8MT",
        "outputId": "efaf32d3-d777-4886-9c33-3e9f05fdb416"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.99313545, 0.00686451], dtype=float32),\n",
              " array([0.99317205, 0.00682802], dtype=float32),\n",
              " array([0.00237298, 0.9976271 ], dtype=float32),\n",
              " array([0.9907075 , 0.00929242], dtype=float32),\n",
              " array([0.9860081, 0.0139919], dtype=float32),\n",
              " array([0.00645875, 0.99354124], dtype=float32),\n",
              " array([0.06209081, 0.9379092 ], dtype=float32),\n",
              " array([0.00857018, 0.99142987], dtype=float32),\n",
              " array([0.89340895, 0.10659109], dtype=float32),\n",
              " array([0.99232554, 0.00767445], dtype=float32),\n",
              " array([0.81555647, 0.18444352], dtype=float32),\n",
              " array([0.9877137, 0.0122863], dtype=float32),\n",
              " array([0.03223534, 0.9677646 ], dtype=float32),\n",
              " array([0.4306993, 0.5693007], dtype=float32),\n",
              " array([0.9816206 , 0.01837934], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkRCiyorosyn",
        "outputId": "1ea46d3e-c995-405a-e80b-f76a65ad6aa6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99313545"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_pred[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-S5G2ialFB3",
        "outputId": "9cdbec17-e75e-42a5-be64-94f90b6ef9e0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "01 - class 1 - tad \n",
        "\n",
        "10 - class 0 - left \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fa4AYevFoDRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred_class = []\n",
        "for i in range(len(data_pred)):\n",
        "  if data_pred[i][0] > data_pred[i][1]:\n",
        "    data_pred_class.append(0) #left\n",
        "  else: \n",
        "    data_pred_class.append(1) #right\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "X1fzbbVLoG6T"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DepBgHXqBdz",
        "outputId": "320cbda0-8527-4dca-a414-542823ecc8c7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1650"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-7QVqULpKhg",
        "outputId": "bfe5a872-9355-47ad-f970-037d0ceee547"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d1,d2 = [],[]\n",
        "with h5py.File('/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5', 'r') as f:\n",
        "    d1 = f['test_data'][:].tolist()\n",
        "    d2 = f['test_labels'][:].tolist()\n",
        "   "
      ],
      "metadata": {
        "id": "6fZ38NZ3oAtr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(d2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38JU-T25pi74",
        "outputId": "96e4121d-03ca-49e0-aa81-d78b1345e88f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2[0] == [1.0, 0.0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOTeCDdepq8g",
        "outputId": "75b42f08-40f9-4153-bcad-5d91fc1be46f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_orig_class = []\n",
        "for i in range(len(d2)):\n",
        "  if(d2[i] == [1.0, 0.0]):\n",
        "    data_orig_class.append(0)\n",
        "  else:\n",
        "    data_orig_class.append(1)\n"
      ],
      "metadata": {
        "id": "mRfU3oZCpnM2"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_orig_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2giXj4EpdHH",
        "outputId": "fd6cb086-e59f-404a-a538-d3ccb9e67691"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy \n",
        "import sklearn\n",
        "sklearn.metrics.accuracy_score(data_orig_class, data_pred_class, normalize=True, sample_weight=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGW3jEvAp-xv",
        "outputId": "5a95cd0e-5ef7-4f2b-e726-13eb768fde19"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5618181818181818"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zFgIH-toqHzJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}