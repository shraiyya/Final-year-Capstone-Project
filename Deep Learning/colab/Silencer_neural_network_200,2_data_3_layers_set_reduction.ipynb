{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Silencer neural network- 200,2 data - 3 layers set reduction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/radhikasethi2011/SilencerEnhancerPredict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsGdEyz9ej92",
        "outputId": "afb413d7-f9d6-40bd-fb58-f835b0454153"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SilencerEnhancerPredict'...\n",
            "remote: Enumerating objects: 298, done.\u001b[K\n",
            "remote: Counting objects: 100% (298/298), done.\u001b[K\n",
            "remote: Compressing objects: 100% (262/262), done.\u001b[K\n",
            "remote: Total 298 (delta 144), reused 68 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (298/298), 151.04 MiB | 11.49 MiB/s, done.\n",
            "Resolving deltas: 100% (144/144), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/SilencerEnhancerPredict/examples/"
      ],
      "metadata": {
        "id": "iulfH4gnhoxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24c94117-bd76-4fdb-90bf-22102bf4444d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SilencerEnhancerPredict/examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from sklearn import metrics\n",
        "import h5py\n",
        "import os"
      ],
      "metadata": {
        "id": "SCMSlHzvoM7o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_LENGTH = 200\n",
        "EPOCH = 200\n",
        "BATCH_SIZE = 64\n",
        "WORK_DIR = \"./\""
      ],
      "metadata": {
        "id": "909G7HHhqf0B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('model.hdf5')"
      ],
      "metadata": {
        "id": "-zQSwuaJh4il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecbd0d5-e2ff-4bfa-d58b-afbc4d11e6dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYNvJsv7leZ_",
        "outputId": "01e87000-dfae-40a6-fefb-f1eb8d660151"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 992, 480)          17760     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 992, 480)         1920      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 992, 480)          0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 328, 480)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 328, 480)          0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 325, 480)          922080    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 325, 480)         1920      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 325, 480)          0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 161, 480)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 161, 480)          0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 158, 240)          461040    \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 52, 240)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 52, 240)           0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 49, 320)           307520    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 49, 320)          1280      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 49, 320)           0         \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 16, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 13, 320)           409920    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 13, 320)          1280      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 13, 320)           0         \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 4, 320)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 180)               230580    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 543       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,355,843\n",
            "Trainable params: 2,352,643\n",
            "Non-trainable params: 3,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqk45uRWaH0k",
        "outputId": "6b3284d9-64a5-4fb1-ed8e-ac6dc9044d34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 1000, 4),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'conv1d_1_input',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 1000, 4),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (9,),\n",
              "    'name': 'conv1d_1',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_1',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_1',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_1',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (9,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_1',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 0.9}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_2',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_2',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_2',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_2',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (2,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_2',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 240,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_3',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_3',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_3',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 320,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_4',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_3',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_3',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_4',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 320,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (4,),\n",
              "    'name': 'conv1d_5',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization_4',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu_4',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d_5',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (4,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Flatten',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'flatten_1',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'sigmoid',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense_1',\n",
              "    'trainable': True,\n",
              "    'units': 180,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'softmax',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense_2',\n",
              "    'trainable': True,\n",
              "    'units': 3,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_file = os.path.join('./examples', \"model_weights.hdf5\")\n",
        "model_file = os.path.join('./examples', \"single_model.hdf5\")\n",
        "model.save(model_file)"
      ],
      "metadata": {
        "id": "VQEkjHcMqAVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767894ef-47e2-477b-e628-9bedae15c51e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_config"
      ],
      "metadata": {
        "id": "tg3r-08QGljQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ae9175-2b09-4335-b4d3-552bed2f5606"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Sequential.get_config of <keras.engine.sequential.Sequential object at 0x7fcb3fd52f10>>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adadelta()"
      ],
      "metadata": {
        "id": "gsHsFed5op0o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODE BASED ON PAPER:"
      ],
      "metadata": {
        "id": "3fA5aQAN38dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import InputLayer, LeakyReLU\n",
        "\n",
        "model1 = Sequential(InputLayer(batch_input_shape= (None, 200, 4),\n",
        "    dtype= 'float32',\n",
        "    ragged= False,\n",
        "    sparse= False))\n",
        "\n",
        "model1.add(Conv1D(activation= 'relu',\n",
        "    activity_regularizer= None,\n",
        "    batch_input_shape= (None, 200, 4),\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer= None,\n",
        "    data_format= 'channels_last',\n",
        "    dilation_rate= (1,),\n",
        "    dtype= 'float32',\n",
        "    filters= 480,\n",
        "    groups= 1,\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
        "    kernel_size= (9,),\n",
        "    padding= 'valid',\n",
        "    strides= (1,),\n",
        "    trainable= True,\n",
        "    use_bias= True))\n",
        "\n",
        "model1.add(BatchNormalization(\n",
        "    beta_constraint= None,\n",
        "    beta_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    beta_regularizer= None,\n",
        "    center= True,\n",
        "    dtype= 'float32',\n",
        "    epsilon= 0.001,\n",
        "    gamma_constraint= None,\n",
        "    gamma_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    gamma_regularizer= None,\n",
        "    momentum= 0.99,\n",
        "    moving_mean_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    moving_variance_initializer= {'class_name': 'Ones', 'config': {}},\n",
        "    scale= True,\n",
        "    trainable=True))\n",
        "\n",
        "model1.add(LeakyReLU(alpha= 0.0,\n",
        "    dtype='float32',\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(MaxPooling1D(data_format= 'channels_last',\n",
        "    dtype= 'float32',\n",
        "    padding='valid',\n",
        "    pool_size=(9,),\n",
        "    strides= (3,),\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(Dropout(dtype= 'float32',\n",
        "    noise_shape= None,\n",
        "    rate= 0.2,\n",
        "    seed= None,\n",
        "    trainable= True))\n",
        "\n",
        "model1.add(Flatten(data_format= 'channels_last',\n",
        "    dtype= 'float32',\n",
        "  trainable= True))\n",
        "\n",
        "model1.add(Dense(180,activation='sigmoid', activity_regularizer=None,\n",
        "    bias_constraint= None,\n",
        "    bias_initializer= {'class_name': 'Zeros', 'config': {}},\n",
        "    bias_regularizer=None,\n",
        "    dtype='float32',\n",
        "    kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer={'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}}, \n",
        "     trainable=True,\t\n",
        "    use_bias= True\n",
        "     ))\n",
        "\n",
        "model1.add(Dense(2,activation='softmax',activity_regularizer= None,bias_constraint= None,\n",
        "                 kernel_constraint= {'class_name': 'MaxNorm',\n",
        "     'config': {'axis': 0, 'max_value': 1}},\n",
        "    kernel_initializer= {'class_name': 'VarianceScaling',\n",
        "     'config': {'distribution': 'uniform',\n",
        "      'mode': 'fan_avg',\n",
        "      'scale': 1.0,\n",
        "      'seed': None}},\n",
        "    kernel_regularizer= {'class_name': 'L1L2',\n",
        "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}}\n",
        "     ))\n",
        "\n",
        "model1.build()"
      ],
      "metadata": {
        "id": "umZ3q-2R38di"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "31rs43u238dk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXlD_DvEdklE",
        "outputId": "406fc654-a671-47ac-afdb-132d0e9faf4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 200, 4),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'input_1',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Conv1D',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 200, 4),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'data_format': 'channels_last',\n",
              "    'dilation_rate': (1,),\n",
              "    'dtype': 'float32',\n",
              "    'filters': 480,\n",
              "    'groups': 1,\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'kernel_size': (9,),\n",
              "    'name': 'conv1d',\n",
              "    'padding': 'valid',\n",
              "    'strides': (1,),\n",
              "    'trainable': True,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'BatchNormalization',\n",
              "   'config': {'axis': ListWrapper([2]),\n",
              "    'beta_constraint': None,\n",
              "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'beta_regularizer': None,\n",
              "    'center': True,\n",
              "    'dtype': 'float32',\n",
              "    'epsilon': 0.001,\n",
              "    'gamma_constraint': None,\n",
              "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'gamma_regularizer': None,\n",
              "    'momentum': 0.99,\n",
              "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
              "    'name': 'batch_normalization',\n",
              "    'scale': True,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'LeakyReLU',\n",
              "   'config': {'alpha': 0.0,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'leaky_re_lu',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'MaxPooling1D',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'max_pooling1d',\n",
              "    'padding': 'valid',\n",
              "    'pool_size': (9,),\n",
              "    'strides': (3,),\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.2,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Flatten',\n",
              "   'config': {'data_format': 'channels_last',\n",
              "    'dtype': 'float32',\n",
              "    'name': 'flatten',\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'sigmoid',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense',\n",
              "    'trainable': True,\n",
              "    'units': 180,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'softmax',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': {'class_name': 'MaxNorm',\n",
              "     'config': {'axis': 0, 'max_value': 1}},\n",
              "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
              "     'config': {'distribution': 'uniform',\n",
              "      'mode': 'fan_avg',\n",
              "      'scale': 1.0,\n",
              "      'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L1L2',\n",
              "     'config': {'l1': 9.99999993922529e-09, 'l2': 4.999999987376214e-07}},\n",
              "    'name': 'dense_1',\n",
              "    'trainable': True,\n",
              "    'units': 2,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential_1'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary(expand_nested=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWHceg6zc6aQ",
        "outputId": "6a88266a-5898-4176-e5e6-42dcf039a602"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 192, 480)          17760     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 192, 480)         1920      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 192, 480)          0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 62, 480)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 62, 480)           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 29760)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 180)               5356980   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 362       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,377,022\n",
            "Trainable params: 5,376,062\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(Dfile):\n",
        "\n",
        "    print(\"reading enhancers...\")\n",
        "    data = {}\n",
        "    with h5py.File(Dfile, \"r\") as inf:\n",
        "        for _key in inf:\n",
        "            data[_key] = inf[_key][()]\n",
        "    return data"
      ],
      "metadata": {
        "id": "B_7PwyyCouX0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mo2mQzO-pZPA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gzip -d /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5.gz"
      ],
      "metadata": {
        "id": "KVAanGsOpgvu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset('/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5')"
      ],
      "metadata": {
        "id": "qwqHKgXRo8qE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd20dba-87f4-40ce-b0ad-f02eb2174661"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading enhancers...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data[\"train_data\"]\n",
        "Y_train = data[\"train_labels\"]\n",
        "X_validation = data[\"val_data\"]\n",
        "Y_validation = data[\"val_labels\"]\n",
        "X_test = data[\"test_data\"]\n",
        "Y_test = data[\"test_labels\"]"
      ],
      "metadata": {
        "id": "xZM2J-wBpFNG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_model = model1"
      ],
      "metadata": {
        "id": "rO_OrLseotbT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "'''\n",
        "Y_train = to_categorical(Y_train, num_classes=None)\n",
        "Y_test = to_categorical(Y_test, num_classes=None)\n",
        "Y_validation = to_categorical(Y_validation, num_classes=None)\n",
        "'''\n",
        "\n",
        "\n",
        "_callbacks = []\n",
        "checkpointer = ModelCheckpoint(filepath=weights_file, verbose=1, save_best_only=True)\n",
        "_callbacks.append(checkpointer)\n",
        "earlystopper = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)\n",
        "_callbacks.append(earlystopper)"
      ],
      "metadata": {
        "id": "LPKGM60CouUZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OUR MODEL"
      ],
      "metadata": {
        "id": "jv_q9IA795pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_model.fit(X_train,\n",
        "                    Y_train,\n",
        "                    batch_size=BATCH_SIZE * 1,\n",
        "                    epochs=EPOCH,\n",
        "                    validation_data=(X_validation, Y_validation),\n",
        "                    shuffle=True,\n",
        "                    callbacks=_callbacks, verbose=1)\n",
        "\n",
        "Y_pred = parallel_model.predict(X_test)"
      ],
      "metadata": {
        "id": "FsoVn3nLuwDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114eb4dc-d09a-41f9-ed81-451cc8cd595b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 1.2823 - accuracy: 0.5018\n",
            "Epoch 1: val_loss improved from inf to 0.69685, saving model to ./examples/model_weights.hdf5\n",
            "78/78 [==============================] - 14s 39ms/step - loss: 1.2801 - accuracy: 0.5015 - val_loss: 0.6969 - val_accuracy: 0.4955\n",
            "Epoch 2/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6941 - accuracy: 0.5024\n",
            "Epoch 2: val_loss improved from 0.69685 to 0.69359, saving model to ./examples/model_weights.hdf5\n",
            "78/78 [==============================] - 3s 34ms/step - loss: 0.6941 - accuracy: 0.5031 - val_loss: 0.6936 - val_accuracy: 0.4955\n",
            "Epoch 3/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6941 - accuracy: 0.4951\n",
            "Epoch 3: val_loss did not improve from 0.69359\n",
            "78/78 [==============================] - 3s 33ms/step - loss: 0.6941 - accuracy: 0.4946 - val_loss: 0.6937 - val_accuracy: 0.4955\n",
            "Epoch 4/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.4945\n",
            "Epoch 4: val_loss improved from 0.69359 to 0.69338, saving model to ./examples/model_weights.hdf5\n",
            "78/78 [==============================] - 3s 34ms/step - loss: 0.6944 - accuracy: 0.4944 - val_loss: 0.6934 - val_accuracy: 0.5045\n",
            "Epoch 5/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.4963\n",
            "Epoch 5: val_loss did not improve from 0.69338\n",
            "78/78 [==============================] - 3s 33ms/step - loss: 0.6946 - accuracy: 0.4963 - val_loss: 0.6945 - val_accuracy: 0.5045\n",
            "Epoch 6/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.5059\n",
            "Epoch 6: val_loss did not improve from 0.69338\n",
            "78/78 [==============================] - 3s 33ms/step - loss: 0.6946 - accuracy: 0.5056 - val_loss: 0.6942 - val_accuracy: 0.4955\n",
            "Epoch 7/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.4963\n",
            "Epoch 7: val_loss did not improve from 0.69338\n",
            "78/78 [==============================] - 3s 33ms/step - loss: 0.6944 - accuracy: 0.4961 - val_loss: 0.6935 - val_accuracy: 0.5045\n",
            "Epoch 8/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6950 - accuracy: 0.4947\n",
            "Epoch 8: val_loss did not improve from 0.69338\n",
            "78/78 [==============================] - 2s 32ms/step - loss: 0.6950 - accuracy: 0.4946 - val_loss: 0.6954 - val_accuracy: 0.4955\n",
            "Epoch 9/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6949 - accuracy: 0.4968\n",
            "Epoch 9: val_loss did not improve from 0.69338\n",
            "78/78 [==============================] - 2s 31ms/step - loss: 0.6949 - accuracy: 0.4963 - val_loss: 0.6936 - val_accuracy: 0.4955\n",
            "Epoch 10/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6954 - accuracy: 0.5022\n",
            "Epoch 10: val_loss did not improve from 0.69338\n",
            "78/78 [==============================] - 2s 31ms/step - loss: 0.6955 - accuracy: 0.5017 - val_loss: 0.6952 - val_accuracy: 0.5045\n",
            "Epoch 11/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6947 - accuracy: 0.4986\n",
            "Epoch 11: val_loss did not improve from 0.69338\n",
            "78/78 [==============================] - 3s 33ms/step - loss: 0.6947 - accuracy: 0.4981 - val_loss: 0.6934 - val_accuracy: 0.5045\n",
            "Epoch 12/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6965 - accuracy: 0.4996\n",
            "Epoch 12: val_loss did not improve from 0.69338\n",
            "78/78 [==============================] - 2s 31ms/step - loss: 0.6965 - accuracy: 0.4995 - val_loss: 0.6936 - val_accuracy: 0.4955\n",
            "Epoch 13/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.4990\n",
            "Epoch 13: val_loss did not improve from 0.69338\n",
            "78/78 [==============================] - 3s 32ms/step - loss: 0.6945 - accuracy: 0.4983 - val_loss: 0.6941 - val_accuracy: 0.4955\n",
            "Epoch 14/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6959 - accuracy: 0.4998\n",
            "Epoch 14: val_loss did not improve from 0.69338\n",
            "78/78 [==============================] - 3s 34ms/step - loss: 0.6958 - accuracy: 0.5003 - val_loss: 0.7057 - val_accuracy: 0.4955\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('/content/SilencerEnhancerPredict/examples/model.hdf5')"
      ],
      "metadata": {
        "id": "Nc21tubB38dl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! gunzip /content/SilencerEnhancerPredict/examples/model.hdf5.gz"
      ],
      "metadata": {
        "id": "rxZxlO-OF6i3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "history = model1.fit(input_train, target_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=no_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split)\n",
        "          '''"
      ],
      "metadata": {
        "id": "uqmDJQ4Ivy9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d5136311-dd63-44cd-9915-13267d188a7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhistory = model1.fit(input_train, target_train,\\n          batch_size=batch_size,\\n          epochs=no_epochs,\\n          verbose=verbosity,\\n          validation_split=validation_split)\\n          '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "# To get learning rate\n",
        "print(K.get_value(model1.optimizer.lr))"
      ],
      "metadata": {
        "id": "O3RjK8Zkm5MK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8756ed97-15ff-4e29-fb37-e6c00bbdd740"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gunzip /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5"
      ],
      "metadata": {
        "id": "gtMkJ25yaXBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ddb5639-98ae-4394-afb8-26ef888888a2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5: unknown suffix -- ignored\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install Bio\n",
        "%pip install pybedtools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dgZ8wc1nrz5",
        "outputId": "19ba0d26-65c2-490a-dcc1-f60d79257b4f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Bio\n",
            "  Downloading bio-1.3.8-py3-none-any.whl (269 kB)\n",
            "\u001b[K     || 269 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Bio) (2.23.0)\n",
            "Collecting mygene\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Collecting biopython>=1.79\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     || 2.3 MB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Bio) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->Bio) (1.21.5)\n",
            "Collecting biothings-client>=0.2.6\n",
            "  Downloading biothings_client-0.2.6-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (1.24.3)\n",
            "Installing collected packages: biothings-client, mygene, biopython, Bio\n",
            "Successfully installed Bio-1.3.8 biopython-1.79 biothings-client-0.2.6 mygene-3.2.2\n",
            "Collecting pybedtools\n",
            "  Downloading pybedtools-0.9.0.tar.gz (12.5 MB)\n",
            "\u001b[K     || 12.5 MB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pybedtools) (1.15.0)\n",
            "Collecting pysam\n",
            "  Downloading pysam-0.19.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.0 MB)\n",
            "\u001b[K     || 15.0 MB 28.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pybedtools\n",
            "  Building wheel for pybedtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybedtools: filename=pybedtools-0.9.0-cp37-cp37m-linux_x86_64.whl size=13616851 sha256=891ee68c1300ea047bfbc4adfe4ab9235c564b151c40458216613a2ce4c635dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/44/0d/3a7449885adaf8ebb157da8c3c834a712f48b3b3b84ba51dda\n",
            "Successfully built pybedtools\n",
            "Installing collected packages: pysam, pybedtools\n",
            "Successfully installed pybedtools-0.9.0 pysam-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SilencerEnhancerPredict/train.py /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5 /content/SilencerEnhancerPredict/examples/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f0b3d8-dba2-4297-9837-7651588f48b1",
        "id": "TbR1F6s_wifO"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-12 08:59:02.907276: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "reading enhancers...\n",
            "Epoch 1/200\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.4952\n",
            "Epoch 1: val_loss improved from inf to 0.69628, saving model to /content/SilencerEnhancerPredict/examples/model_weights.hdf5\n",
            "78/78 [==============================] - 6s 46ms/step - loss: 0.6958 - accuracy: 0.4952 - val_loss: 0.6963 - val_accuracy: 0.5045\n",
            "Epoch 2/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6950 - accuracy: 0.4957\n",
            "Epoch 2: val_loss improved from 0.69628 to 0.69354, saving model to /content/SilencerEnhancerPredict/examples/model_weights.hdf5\n",
            "78/78 [==============================] - 3s 37ms/step - loss: 0.6950 - accuracy: 0.4952 - val_loss: 0.6935 - val_accuracy: 0.5045\n",
            "Epoch 3/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.7084 - accuracy: 0.4949\n",
            "Epoch 3: val_loss improved from 0.69354 to 0.69333, saving model to /content/SilencerEnhancerPredict/examples/model_weights.hdf5\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.7084 - accuracy: 0.4944 - val_loss: 0.6933 - val_accuracy: 0.4955\n",
            "Epoch 4/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6952 - accuracy: 0.5018\n",
            "Epoch 4: val_loss did not improve from 0.69333\n",
            "78/78 [==============================] - 3s 36ms/step - loss: 0.6952 - accuracy: 0.5017 - val_loss: 0.6936 - val_accuracy: 0.5045\n",
            "Epoch 5/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6976 - accuracy: 0.4953\n",
            "Epoch 5: val_loss did not improve from 0.69333\n",
            "78/78 [==============================] - 2s 32ms/step - loss: 0.6978 - accuracy: 0.4944 - val_loss: 0.6959 - val_accuracy: 0.5045\n",
            "Epoch 6/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6975 - accuracy: 0.5073\n",
            "Epoch 6: val_loss did not improve from 0.69333\n",
            "78/78 [==============================] - 2s 31ms/step - loss: 0.6974 - accuracy: 0.5074 - val_loss: 0.7001 - val_accuracy: 0.5045\n",
            "Epoch 7/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6960 - accuracy: 0.5018\n",
            "Epoch 7: val_loss did not improve from 0.69333\n",
            "78/78 [==============================] - 2s 31ms/step - loss: 0.6960 - accuracy: 0.5017 - val_loss: 0.6938 - val_accuracy: 0.5045\n",
            "Epoch 8/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6971 - accuracy: 0.4949\n",
            "Epoch 8: val_loss improved from 0.69333 to 0.69332, saving model to /content/SilencerEnhancerPredict/examples/model_weights.hdf5\n",
            "78/78 [==============================] - 3s 33ms/step - loss: 0.6971 - accuracy: 0.4950 - val_loss: 0.6933 - val_accuracy: 0.4955\n",
            "Epoch 9/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6943 - accuracy: 0.5045\n",
            "Epoch 9: val_loss did not improve from 0.69332\n",
            "78/78 [==============================] - 2s 31ms/step - loss: 0.6943 - accuracy: 0.5045 - val_loss: 0.7025 - val_accuracy: 0.4955\n",
            "Epoch 10/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6977 - accuracy: 0.4949\n",
            "Epoch 10: val_loss did not improve from 0.69332\n",
            "78/78 [==============================] - 2s 31ms/step - loss: 0.6976 - accuracy: 0.4952 - val_loss: 0.6934 - val_accuracy: 0.4955\n",
            "Epoch 11/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6972 - accuracy: 0.4959\n",
            "Epoch 11: val_loss did not improve from 0.69332\n",
            "78/78 [==============================] - 2s 31ms/step - loss: 0.6972 - accuracy: 0.4961 - val_loss: 0.6936 - val_accuracy: 0.4955\n",
            "Epoch 12/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6983 - accuracy: 0.4996\n",
            "Epoch 12: val_loss did not improve from 0.69332\n",
            "78/78 [==============================] - 2s 30ms/step - loss: 0.6982 - accuracy: 0.5001 - val_loss: 0.6983 - val_accuracy: 0.4955\n",
            "Epoch 13/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6967 - accuracy: 0.4937\n",
            "Epoch 13: val_loss did not improve from 0.69332\n",
            "78/78 [==============================] - 2s 31ms/step - loss: 0.6966 - accuracy: 0.4938 - val_loss: 0.6937 - val_accuracy: 0.5045\n",
            "Epoch 14/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6940 - accuracy: 0.5002\n",
            "Epoch 14: val_loss did not improve from 0.69332\n",
            "78/78 [==============================] - 2s 29ms/step - loss: 0.6940 - accuracy: 0.5009 - val_loss: 0.6934 - val_accuracy: 0.5045\n",
            "Epoch 15/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.4998\n",
            "Epoch 15: val_loss did not improve from 0.69332\n",
            "78/78 [==============================] - 2s 29ms/step - loss: 0.6944 - accuracy: 0.4995 - val_loss: 0.6935 - val_accuracy: 0.5045\n",
            "Epoch 16/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6951 - accuracy: 0.5045\n",
            "Epoch 16: val_loss did not improve from 0.69332\n",
            "78/78 [==============================] - 2s 30ms/step - loss: 0.6952 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4955\n",
            "Epoch 17/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6949 - accuracy: 0.4974\n",
            "Epoch 17: val_loss did not improve from 0.69332\n",
            "78/78 [==============================] - 2s 30ms/step - loss: 0.6949 - accuracy: 0.4973 - val_loss: 0.6949 - val_accuracy: 0.4955\n",
            "Epoch 18/200\n",
            "77/78 [============================>.] - ETA: 0s - loss: 0.6961 - accuracy: 0.4929\n",
            "Epoch 18: val_loss did not improve from 0.69332\n",
            "78/78 [==============================] - 2s 30ms/step - loss: 0.6961 - accuracy: 0.4926 - val_loss: 0.6936 - val_accuracy: 0.4955\n",
            "Epoch 18: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import h5py\n",
        "filename = \"/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5\"\n",
        "\n",
        "with h5py.File(filename, \"r\") as f:\n",
        "    # List all groups\n",
        "    print(\"Keys: %s\" % f.keys())\n",
        "    a_group_key = list(f.keys())[0]\n",
        "\n",
        "    # Get the data\n",
        "    data = list(f[a_group_key])\n",
        "    \n",
        "    print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da0c367-d26c-4bd6-c343-25b7ca8dd2f3",
        "id": "e2fmhqerwifT"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: <KeysViewHDF5 ['test_data', 'test_labels', 'train_data', 'train_labels', 'val_data', 'val_labels']>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File(filename, \"r\") as h5f:\n",
        "    # Get a h5py dataset object\n",
        "    data_ds = h5f['test_data']\n",
        "    print ('data_ds dtype:', data_ds.dtype, '\\nshape:', data_ds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20QURFhYOEeq",
        "outputId": "394d9272-fde1-432d-a7fd-e9e444b5840a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_ds dtype: float64 \n",
            "shape: (1650, 200, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nsfT9SAO3gQ",
        "outputId": "81ba03a9-7a79-4a76-f887-1e4211408a98"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Closed HDF5 dataset>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ba86a1-31eb-4b55-8beb-7869e983e82a",
        "id": "JrXJgnGewifW"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9c89ad-493a-4bc4-cc0c-19fd87dc720f",
        "id": "H3WYInnewifW"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1650"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SilencerEnhancerPredict/predict.py /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5 /content/SilencerEnhancerPredict/examples/model_weights.hdf5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_gGYsRKnmP7",
        "outputId": "b9049ede-1f29-47af-bf42-b44bee36194d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-12 09:00:47.374453: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "reading samples...\n",
            "prediction on test samples ...\n",
            "9/9 [==============================] - 1s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# reading from the file\n",
        "path=\"/content/SilencerEnhancerPredict/examples/data_prediction.hdf5.pred.data\"\n",
        "with open(path, 'rb') as f:\n",
        "  contents = f.read()\n",
        "contents\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "94rQ49Pcu3cs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6c494ba1-7ca1-477d-ee6e-3ab2be1d8ce7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# reading from the file\\npath=\"/content/SilencerEnhancerPredict/examples/data_prediction.hdf5.pred.data\"\\nwith open(path, \\'rb\\') as f:\\n  contents = f.read()\\ncontents\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import h5py\n",
        "filename = \"/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5\"\n",
        "\n",
        "with h5py.File(filename, \"r\") as f:\n",
        "    # List all groups\n",
        "    print(\"Keys: %s\" % f.keys())\n",
        "    a_group_key = list(f.keys())[0]\n",
        "\n",
        "    # Get the data\n",
        "    data = list(f[a_group_key])\n",
        "    #print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEJ_Q9LPcsaB",
        "outputId": "6604ba0b-7cba-4f6a-e779-db549725b183"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: <KeysViewHDF5 ['test_data', 'test_labels', 'train_data', 'train_labels', 'val_data', 'val_labels']>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "id": "0IkUDiXJankE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd5f9e1-68e0-4849-a468-8f5c226628a5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "bYt4hI59awVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fe39ab-e58e-46bf-ec1d-fbb8c892bffb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1650"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0])"
      ],
      "metadata": {
        "id": "gX1EDAagayKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4f22f8-a56d-49ed-8f06-1102fbe7f606"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUIfhzY9a0mS",
        "outputId": "b3bce12b-35d5-4231-9087-f7c113528da1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f= '/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5.pred.data'"
      ],
      "metadata": {
        "id": "bxTAzFKXNlO8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "with h5py.File(f, \"r\") as f:\n",
        "    # List all groups\n",
        "    print(\"Keys: %s\" % f.keys())\n",
        "    a_group_key = list(f.keys())[0]\n",
        "\n",
        "    # Get the data\n",
        "    data_pred = list(f[a_group_key])\n",
        "    #print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfoLXAJNP5mI",
        "outputId": "5f4ddb16-5a37-46a9-d6b1-14ea31f017f7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: <KeysViewHDF5 ['ypred']>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data_pred))"
      ],
      "metadata": {
        "id": "Wm_HIPwkjbQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7360e419-2f26-4e50-af21-fc0e7d6be59c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtLnpMqKk8MT",
        "outputId": "3d0067ce-5112-4081-cb0a-f08101312a93"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.5027083 , 0.49729168], dtype=float32),\n",
              " array([0.50334406, 0.49665594], dtype=float32),\n",
              " array([0.5024285, 0.4975715], dtype=float32),\n",
              " array([0.50246996, 0.49753004], dtype=float32),\n",
              " array([0.50279796, 0.49720204], dtype=float32),\n",
              " array([0.502457  , 0.49754298], dtype=float32),\n",
              " array([0.5025035 , 0.49749643], dtype=float32),\n",
              " array([0.5024192, 0.4975808], dtype=float32),\n",
              " array([0.5024132, 0.4975868], dtype=float32),\n",
              " array([0.5026474 , 0.49735263], dtype=float32),\n",
              " array([0.5024541 , 0.49754593], dtype=float32),\n",
              " array([0.50434935, 0.49565065], dtype=float32),\n",
              " array([0.5024237, 0.4975763], dtype=float32),\n",
              " array([0.5025811 , 0.49741888], dtype=float32),\n",
              " array([0.5025246 , 0.49747536], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkRCiyorosyn",
        "outputId": "ca53e1a3-6ab0-42ac-c743-047bca7e3403"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5027083"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_pred[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-S5G2ialFB3",
        "outputId": "c7350e1c-e90e-472a-d440-1c4796e83420"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "01 - class 1 - tad \n",
        "\n",
        "10 - class 0 - left \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fa4AYevFoDRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred_class = []\n",
        "for i in range(len(data_pred)):\n",
        "  if data_pred[i][0] > data_pred[i][1]:\n",
        "    data_pred_class.append(0) #left\n",
        "  else: \n",
        "    data_pred_class.append(1) #right\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "X1fzbbVLoG6T"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DepBgHXqBdz",
        "outputId": "106f2f4c-b090-4c28-e309-1524626311c7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1650"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pred_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-7QVqULpKhg",
        "outputId": "0978ea9b-dd0b-4f08-805e-1f63b4018725"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d1,d2 = [],[]\n",
        "with h5py.File('/content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5', 'r') as f:\n",
        "    d1 = f['test_data'][:].tolist()\n",
        "    d2 = f['test_labels'][:].tolist()\n",
        "   "
      ],
      "metadata": {
        "id": "6fZ38NZ3oAtr"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(d2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38JU-T25pi74",
        "outputId": "38d6a4e0-e20f-4669-e2e1-e793dd17e0c9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2[0] == [1.0, 0.0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOTeCDdepq8g",
        "outputId": "c58778e1-f60d-4a38-d32e-6ded86936a31"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_orig_class = []\n",
        "for i in range(len(d2)):\n",
        "  if(d2[i] == [1.0, 0.0]):\n",
        "    data_orig_class.append(0)\n",
        "  else:\n",
        "    data_orig_class.append(1)\n"
      ],
      "metadata": {
        "id": "mRfU3oZCpnM2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_orig_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2giXj4EpdHH",
        "outputId": "be7befdd-7724-4620-f7b0-1c5cc57d7734"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy \n",
        "import sklearn\n",
        "sklearn.metrics.accuracy_score(data_orig_class, data_pred_class, normalize=True, sample_weight=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGW3jEvAp-xv",
        "outputId": "1331ad4c-c367-40f4-f9fe-4d964a6205bd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4903030303030303"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}