{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsGdEyz9ej92",
        "outputId": "967b6ff7-40ac-4278-ea04-3e450a55ac6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SilencerEnhancerPredict'...\n",
            "remote: Enumerating objects: 401, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 401 (delta 10), reused 0 (delta 0), pack-reused 375\u001b[K\n",
            "Receiving objects: 100% (401/401), 199.49 MiB | 16.80 MiB/s, done.\n",
            "Resolving deltas: 100% (190/190), done.\n",
            "Checking out files: 100% (77/77), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/radhikasethi2011/SilencerEnhancerPredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SCMSlHzvoM7o"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from sklearn import metrics\n",
        "import h5py\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3oFoh8nkdyY",
        "outputId": "8c091a53-d378-491b-a0f9-efb235cddcc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SilencerEnhancerPredict\n"
          ]
        }
      ],
      "source": [
        "cd '/content/SilencerEnhancerPredict'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ev-acXVmknqp",
        "outputId": "6203479a-cb30-4aa3-ccf8-4a40f7c1db14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/SilencerEnhancerPredict'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gtMkJ25yaXBP"
      },
      "outputs": [],
      "source": [
        "! gunzip /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dgZ8wc1nrz5",
        "outputId": "11180640-4448-405b-e593-21f0c21a630e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Bio\n",
            "  Downloading bio-1.3.8-py3-none-any.whl (269 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 39.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 37.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 153 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 163 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 174 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 184 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 194 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 269 kB 33.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Bio) (2.23.0)\n",
            "Collecting biopython>=1.79\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 41.0 MB/s \n",
            "\u001b[?25hCollecting mygene\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Bio) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->Bio) (1.21.6)\n",
            "Collecting biothings-client>=0.2.6\n",
            "  Downloading biothings_client-0.2.6-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (1.24.3)\n",
            "Installing collected packages: biothings-client, mygene, biopython, Bio\n",
            "Successfully installed Bio-1.3.8 biopython-1.79 biothings-client-0.2.6 mygene-3.2.2\n",
            "Collecting pybedtools\n",
            "  Downloading pybedtools-0.9.0.tar.gz (12.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 35.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pybedtools) (1.15.0)\n",
            "Collecting pysam\n",
            "  Downloading pysam-0.19.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.0 MB 34.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pybedtools\n",
            "  Building wheel for pybedtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybedtools: filename=pybedtools-0.9.0-cp37-cp37m-linux_x86_64.whl size=13616801 sha256=be2727acb382e951facbcb879a053b474eaf2badf8cde9aa3d89930bf4654cdd\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/44/0d/3a7449885adaf8ebb157da8c3c834a712f48b3b3b84ba51dda\n",
            "Successfully built pybedtools\n",
            "Installing collected packages: pysam, pybedtools\n",
            "Successfully installed pybedtools-0.9.0 pysam-0.19.0\n"
          ]
        }
      ],
      "source": [
        "%pip install Bio\n",
        "%pip install pybedtools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8VdJs3S5ZZz",
        "outputId": "4d51eac4-b6dc-4084-e917-9a27881b28e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1tbv0cap7bmR",
        "outputId": "252ff3a9-ac7b-40ee-e91b-f639e0b3d14a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "g795zYWLYklN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib notebook"
      ],
      "metadata": {
        "id": "5-IuO_AQZ-9-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2lE7bPohArJ",
        "outputId": "0e0988db-6c55-4ef8-93a3-dfce6597fa25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-10 12:06:30.979109: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "reading enhancers...\n",
            "1\n",
            " \n",
            "Epoch 1/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.7846\n",
            "Epoch 1: val_loss improved from inf to 0.61930, saving model to /content/SilencerEnhancerPredict/examples/model_weights.hdf5\n",
            "73/73 [==============================] - 7s 34ms/step - loss: 0.4861 - accuracy: 0.7846 - val_loss: 0.6193 - val_accuracy: 0.6669\n",
            "Epoch 2/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8579\n",
            "Epoch 2: val_loss improved from 0.61930 to 0.47162, saving model to /content/SilencerEnhancerPredict/examples/model_weights.hdf5\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.3297 - accuracy: 0.8579 - val_loss: 0.4716 - val_accuracy: 0.7878\n",
            "Epoch 3/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9099\n",
            "Epoch 3: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.2248 - accuracy: 0.9099 - val_loss: 0.7826 - val_accuracy: 0.6979\n",
            "Epoch 4/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.9239\n",
            "Epoch 4: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.1951 - accuracy: 0.9239 - val_loss: 0.7957 - val_accuracy: 0.6928\n",
            "Epoch 5/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.9362\n",
            "Epoch 5: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.1623 - accuracy: 0.9362 - val_loss: 0.7002 - val_accuracy: 0.7212\n",
            "Epoch 6/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.9463\n",
            "Epoch 6: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.1343 - accuracy: 0.9463 - val_loss: 0.6796 - val_accuracy: 0.7561\n",
            "Epoch 7/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.9508\n",
            "Epoch 7: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.1272 - accuracy: 0.9508 - val_loss: 1.0586 - val_accuracy: 0.6785\n",
            "Epoch 8/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9564\n",
            "Epoch 8: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.1150 - accuracy: 0.9564 - val_loss: 1.1655 - val_accuracy: 0.6772\n",
            "Epoch 9/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9646\n",
            "Epoch 9: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.1026 - accuracy: 0.9646 - val_loss: 0.8135 - val_accuracy: 0.7102\n",
            "Epoch 10/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9649\n",
            "Epoch 10: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.0933 - accuracy: 0.9649 - val_loss: 0.8214 - val_accuracy: 0.7147\n",
            "Epoch 11/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9659\n",
            "Epoch 11: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0954 - accuracy: 0.9659 - val_loss: 1.0402 - val_accuracy: 0.6798\n",
            "Epoch 12/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9642\n",
            "Epoch 12: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0940 - accuracy: 0.9642 - val_loss: 0.8802 - val_accuracy: 0.7102\n",
            "Epoch 12: early stopping\n",
            " \n",
            "Score for fold 1: loss of 0.8694615960121155; accuracy of 69.8836088180542%\n",
            "reading samples...\n",
            "prediction on test samples ...\n",
            "11/11 [==============================] - 1s 21ms/step\n",
            "Keys: <KeysViewHDF5 ['ypred']>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "2\n",
            " \n",
            "Epoch 1/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.8609\n",
            "Epoch 1: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.3521 - accuracy: 0.8609 - val_loss: 0.7059 - val_accuracy: 0.6662\n",
            "Epoch 2/200\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9266\n",
            "Epoch 2: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.1901 - accuracy: 0.9269 - val_loss: 0.8486 - val_accuracy: 0.6481\n",
            "Epoch 3/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9508\n",
            "Epoch 3: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.1347 - accuracy: 0.9508 - val_loss: 0.9712 - val_accuracy: 0.6617\n",
            "Epoch 4/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9605\n",
            "Epoch 4: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.1112 - accuracy: 0.9605 - val_loss: 0.9596 - val_accuracy: 0.6624\n",
            "Epoch 5/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9683\n",
            "Epoch 5: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0901 - accuracy: 0.9683 - val_loss: 1.3656 - val_accuracy: 0.6235\n",
            "Epoch 6/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9657\n",
            "Epoch 6: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0919 - accuracy: 0.9657 - val_loss: 1.2594 - val_accuracy: 0.6339\n",
            "Epoch 7/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9679\n",
            "Epoch 7: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0821 - accuracy: 0.9679 - val_loss: 1.1346 - val_accuracy: 0.6404\n",
            "Epoch 8/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9759\n",
            "Epoch 8: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0719 - accuracy: 0.9759 - val_loss: 1.0698 - val_accuracy: 0.6429\n",
            "Epoch 9/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9670\n",
            "Epoch 9: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0851 - accuracy: 0.9670 - val_loss: 1.2537 - val_accuracy: 0.6552\n",
            "Epoch 10/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9711\n",
            "Epoch 10: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.0805 - accuracy: 0.9711 - val_loss: 1.2952 - val_accuracy: 0.6332\n",
            "Epoch 11/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9756\n",
            "Epoch 11: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0618 - accuracy: 0.9756 - val_loss: 1.1188 - val_accuracy: 0.6669\n",
            "Epoch 11: early stopping\n",
            " \n",
            "Score for fold 2: loss of 0.4349414110183716; accuracy of 84.86905694007874%\n",
            "reading samples...\n",
            "prediction on test samples ...\n",
            "11/11 [==============================] - 0s 15ms/step\n",
            "Keys: <KeysViewHDF5 ['ypred']>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "3\n",
            " \n",
            "Epoch 1/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9310\n",
            "Epoch 1: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 30ms/step - loss: 0.1827 - accuracy: 0.9310 - val_loss: 0.9112 - val_accuracy: 0.6574\n",
            "Epoch 2/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9638\n",
            "Epoch 2: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0973 - accuracy: 0.9638 - val_loss: 1.0946 - val_accuracy: 0.6593\n",
            "Epoch 3/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9661\n",
            "Epoch 3: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0831 - accuracy: 0.9661 - val_loss: 1.0938 - val_accuracy: 0.6600\n",
            "Epoch 4/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9735\n",
            "Epoch 4: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0740 - accuracy: 0.9735 - val_loss: 1.2362 - val_accuracy: 0.6406\n",
            "Epoch 5/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9735\n",
            "Epoch 5: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.0739 - accuracy: 0.9735 - val_loss: 1.3675 - val_accuracy: 0.6322\n",
            "Epoch 6/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9806\n",
            "Epoch 6: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0549 - accuracy: 0.9806 - val_loss: 1.2041 - val_accuracy: 0.6723\n",
            "Epoch 7/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9797\n",
            "Epoch 7: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.0581 - accuracy: 0.9797 - val_loss: 1.1361 - val_accuracy: 0.6684\n",
            "Epoch 8/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9808\n",
            "Epoch 8: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0521 - accuracy: 0.9808 - val_loss: 1.1950 - val_accuracy: 0.6703\n",
            "Epoch 9/200\n",
            "71/73 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9740\n",
            "Epoch 9: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 26ms/step - loss: 0.0659 - accuracy: 0.9739 - val_loss: 1.0802 - val_accuracy: 0.6690\n",
            "Epoch 10/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9787\n",
            "Epoch 10: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0602 - accuracy: 0.9787 - val_loss: 1.1181 - val_accuracy: 0.6632\n",
            "Epoch 11/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9828\n",
            "Epoch 11: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0498 - accuracy: 0.9828 - val_loss: 1.1768 - val_accuracy: 0.6677\n",
            "Epoch 11: early stopping\n",
            " \n",
            "Score for fold 3: loss of 0.3780953884124756; accuracy of 88.11256885528564%\n",
            "reading samples...\n",
            "prediction on test samples ...\n",
            "11/11 [==============================] - 0s 21ms/step\n",
            "Keys: <KeysViewHDF5 ['ypred']>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "4\n",
            " \n",
            "Epoch 1/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9569\n",
            "Epoch 1: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.1148 - accuracy: 0.9569 - val_loss: 1.1942 - val_accuracy: 0.6167\n",
            "Epoch 2/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9679\n",
            "Epoch 2: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.0800 - accuracy: 0.9679 - val_loss: 1.4530 - val_accuracy: 0.5921\n",
            "Epoch 3/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9698\n",
            "Epoch 3: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.0796 - accuracy: 0.9698 - val_loss: 1.3298 - val_accuracy: 0.6419\n",
            "Epoch 4/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9804\n",
            "Epoch 4: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.0538 - accuracy: 0.9804 - val_loss: 1.2439 - val_accuracy: 0.6464\n",
            "Epoch 5/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9806\n",
            "Epoch 5: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.0534 - accuracy: 0.9806 - val_loss: 1.3554 - val_accuracy: 0.6231\n",
            "Epoch 6/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9787\n",
            "Epoch 6: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.0612 - accuracy: 0.9787 - val_loss: 1.2358 - val_accuracy: 0.6315\n",
            "Epoch 7/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9763\n",
            "Epoch 7: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0632 - accuracy: 0.9763 - val_loss: 1.3068 - val_accuracy: 0.6283\n",
            "Epoch 8/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9752\n",
            "Epoch 8: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.0693 - accuracy: 0.9752 - val_loss: 1.2456 - val_accuracy: 0.6270\n",
            "Epoch 9/200\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9835\n",
            "Epoch 9: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.0436 - accuracy: 0.9836 - val_loss: 1.4654 - val_accuracy: 0.6186\n",
            "Epoch 10/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9847\n",
            "Epoch 10: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 1.3796 - val_accuracy: 0.6380\n",
            "Epoch 11/200\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9884\n",
            "Epoch 11: val_loss did not improve from 0.47162\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 1.4472 - val_accuracy: 0.6160\n",
            "Epoch 11: early stopping\n",
            " \n",
            "Score for fold 4: loss of 0.3533502519130707; accuracy of 89.81077075004578%\n",
            "reading samples...\n",
            "prediction on test samples ...\n",
            "11/11 [==============================] - 0s 15ms/step\n",
            "Keys: <KeysViewHDF5 ['ypred']>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.8694615960121155 - Accuracy: 69.8836088180542%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.4349414110183716 - Accuracy: 84.86905694007874%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.3780953884124756 - Accuracy: 88.11256885528564%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.3533502519130707 - Accuracy: 89.81077075004578%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 83.16900134086609 (+- 7.8731157139333945)\n",
            "> Loss: 0.5089621618390083\n",
            "------------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SilencerEnhancerPredict/train.py\", line 242, in <module>\n",
            "    train_model(data,results_dir)\n",
            "  File \"/content/SilencerEnhancerPredict/train.py\", line 232, in train_model\n",
            "    run_model(data, model, results_dir)\n",
            "  File \"/content/SilencerEnhancerPredict/train.py\", line 174, in run_model\n",
            "    of.write(test_acc_per_fold)\n",
            "TypeError: write() argument must be str, not list\n"
          ]
        }
      ],
      "source": [
        "!python /content/SilencerEnhancerPredict/train.py /content/SilencerEnhancerPredict/examples/training_200seq_2class.hdf5 /content/SilencerEnhancerPredict/examples/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VEzDVraryifk"
      },
      "outputs": [],
      "source": [
        "test_auc =[0.7885548011639185, 0.906886517943744, 0.898592916060165, 0.9019893255701116]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.09900990099009901,0.09900990099009901,0.09900990099009901,0.09900990099009901,0.09801980198019802,0.09801980198019802,0.09702970297029703,0.09702970297029703,0.09702970297029703,0.09702970297029703,0.09702970297029703,0.09702970297029703,0.09702970297029703,0.09702970297029703,0.09603960396039604,0.09603960396039604,0.09504950495049505,0.09504950495049505,0.09405940594059406,0.09405940594059406,0.09306930693069307,0.09306930693069307,0.09207920792079208,0.09207920792079208,0.0910891089108911,0.0910891089108911,0.0910891089108911,0.0910891089108911,0.09009900990099011,0.09009900990099011,0.08910891089108912,0.08910891089108912,0.08811881188118813,0.08811881188118813,0.08712871287128714,0.08712871287128714,0.08613861386138615,0.08613861386138615,0.08514851485148515,0.08514851485148515,0.08415841584158416,0.08415841584158416,0.08316831683168317,0.08316831683168317,0.08217821782178218,0.08217821782178218,0.08118811881188119,0.08118811881188119,0.0801980198019802,0.0801980198019802,0.07920792079207921,0.07920792079207921,0.07821782178217823,0.07821782178217823,0.07722772277227724,0.07722772277227724,0.07623762376237625,0.07623762376237625,0.07524752475247526,0.07524752475247526,0.07425742574257427,0.07425742574257427,0.07326732673267328,0.07326732673267328,0.07227722772277229,0.07227722772277229,0.0712871287128713,0.0712871287128713,0.0702970297029703,0.0702970297029703,0.06930693069306931,0.06930693069306931,0.06831683168316832,0.06831683168316832,0.06732673267326733,0.06732673267326733,0.06633663366336634,0.06633663366336634,0.06534653465346535,0.06534653465346535,0.06435643564356436,0.06435643564356436,0.06237623762376238,0.06237623762376238,0.0603960396039604,0.0603960396039604,0.05841584158415842,0.05841584158415842,0.05742574257425743,0.05742574257425743,0.056435643564356444,0.056435643564356444,0.05544554455445545,0.05544554455445545,0.05445544554455446,0.05445544554455446,0.05247524752475248,0.05247524752475248,0.05148514851485149,0.05148514851485149,0.04950495049504951,0.04950495049504951,0.04851485148514852,0.04851485148514852,0.04752475247524753,0.04752475247524753,0.04455445544554456,0.04455445544554456,0.04257425742574258,0.04257425742574258,0.03861386138613862,0.03861386138613862,0.034653465346534656,0.034653465346534656,0.032673267326732675,0.032673267326732675,0.031683168316831684,0.031683168316831684,0.030693069306930693,0.030693069306930693,0.0297029702970297,0.0297029702970297,0.028712871287128724,0.028712871287128724,0.027722772277227734,0.027722772277227734,0.026732673267326743,0.026732673267326743,0.02574257425742575,0.02574257425742575,0.02475247524752476,0.02475247524752476,0.02376237623762377,0.02376237623762377,0.02277227722772278,0.02277227722772278,0.019801980198019806,0.019801980198019806,0.017821782178217824,0.017821782178217824,0.016831683168316833,0.016831683168316833,0.015841584158415842,0.015841584158415842,0.013861386138613874,0.013861386138613874,0.012871287128712883,0.012871287128712883,0.011881188118811892,0.011881188118811892,0.0108910891089109,0.0108910891089109,0.00990099009900991,0.00990099009900991,0.008910891089108919,0.008910891089108919,0.007920792079207928,0.007920792079207928,0.006930693069306937,0.006930693069306937,0.005940594059405946,0.005940594059405946,0.003960396039603964,0.003960396039603964,0.001980198019801982,0.001980198019801982,0.0,0.0,0.000990099009900991,0.000990099009900991,0.001980198019801968,0.001980198019801968,0.002970297029702959,0.002970297029702959,0.005940594059405932,0.005940594059405932,0.006930693069306923,0.006930693069306923,0.007920792079207914,0.007920792079207914,0.01485148514851485,0.01485148514851485,0.015841584158415842,0.015841584158415842,0.01782178217821781,0.01782178217821781,0.0188118811881188,0.0188118811881188,0.019801980198019792,0.019801980198019792,0.020792079207920783,0.020792079207920783,0.021782178217821774,0.021782178217821774,0.025742574257425738,0.025742574257425738,0.02673267326732673,0.02673267326732673,0.032673267326732675,0.032673267326732675,0.033663366336633666,0.033663366336633666,0.03564356435643565,0.03564356435643565,0.03762376237623763,0.03762376237623763,0.03861386138613862,0.03861386138613862,0.04257425742574256,0.04257425742574256,0.04356435643564355,0.04356435643564355,0.04455445544554454,0.04455445544554454,0.04752475247524751,0.04752475247524751,0.052475247524752466,0.052475247524752466,0.05544554455445544,0.05544554455445544,0.062376237623762376,0.062376237623762376,0.06930693069306931,0.06930693069306931,0.0702970297029703,0.0702970297029703,0.07722772277227721,0.07722772277227721,0.08514851485148514,0.08514851485148514,0.08811881188118811,0.08811881188118811,0.0891089108910891,0.0891089108910891,0.09504950495049505,0.09504950495049505,0.09702970297029703,0.09702970297029703,0.100990099009901,0.100990099009901,0.1089108910891089,0.1089108910891089,0.11287128712871286,0.11287128712871286,0.11485148514851484,0.11485148514851484,0.11782178217821782,0.11782178217821782,0.12376237623762376,0.12376237623762376,0.12475247524752475,0.12475247524752475,0.1306930693069307,0.1306930693069307,0.13267326732673268,0.13267326732673268,0.14158415841584157,0.14158415841584157,0.14257425742574256,0.14257425742574256,0.15148514851485148,0.15148514851485148,0.15445544554455445,0.15445544554455445,0.15643564356435644,0.15643564356435644,0.1613861386138614,0.1613861386138614,0.16336633663366337,0.16336633663366337,0.17326732673267328,0.17326732673267328,0.1881188118811881,0.1881188118811881,0.199009900990099,0.199009900990099,0.20495049504950494,0.20495049504950494,0.2099009900990099,0.2099009900990099,0.21683168316831683,0.21683168316831683,0.2207920792079208,0.2207920792079208,0.22475247524752476,0.22475247524752476,0.2405940594059406,0.2405940594059406,0.2475247524752475,0.2475247524752475,0.26534653465346536,0.26534653465346536,0.26732673267326734,0.26732673267326734,0.2693069306930693,0.2693069306930693,0.27623762376237626,0.27623762376237626,0.30000000000000004,0.30000000000000004,0.34356435643564354,0.34356435643564354,0.3821782178217822,0.3821782178217822,0.3920792079207921,0.3920792079207921,0.404950495049505,0.404950495049505,0.4346534653465347,0.4346534653465347,0.45049504950495056,0.45049504950495056,0.46336633663366333,0.46336633663366333,0.4653465346534653,0.4653465346534653,0.4673267326732673,0.4673267326732673,0.48415841584158414,0.48415841584158414,0.5524752475247525,0.5524752475247525,0.601980198019802,0.601980198019802,0.6118811881188119,0.6118811881188119,0.6970297029702971,0.6970297029702971,0.7633663366336634,0.7633663366336634,0.8603960396039604,0.8603960396039604,0.9]"
      ],
      "metadata": {
        "id": "Scp6hwWZi4P3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "arr1 =np.argsort(l)\n",
        "arr1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Iw6NIsi6-k",
        "outputId": "dc649a5a-5108-4e59-b8ab-74789bdc7f59"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([175, 176, 177, 178, 179, 180, 173, 174, 182, 181, 171, 172, 184,\n",
              "       183, 170, 169, 185, 186, 167, 168, 187, 188, 166, 165, 164, 163,\n",
              "       162, 161, 160, 159, 157, 158, 155, 156, 154, 153, 189, 190, 151,\n",
              "       152, 191, 192, 150, 149, 193, 194, 147, 148, 195, 196, 197, 198,\n",
              "       145, 146, 200, 199, 201, 202, 143, 144, 141, 142, 139, 140, 204,\n",
              "       203, 137, 138, 206, 205, 135, 136, 133, 134, 132, 131, 129, 130,\n",
              "       128, 127, 125, 126, 123, 207, 208, 124, 210, 209, 121, 122, 212,\n",
              "       211, 214, 213, 120, 119, 215, 216, 217, 218, 117, 118, 219, 220,\n",
              "       222, 221, 115, 116, 224, 223, 113, 114, 112, 111, 110, 109, 108,\n",
              "       107, 225, 226, 106, 105, 103, 104, 227, 228, 101, 102, 100,  99,\n",
              "        97,  98,  95,  96,  94,  93, 230, 229,  91,  92,  90,  89,  88,\n",
              "        87,  85,  86,  83,  84,  81,  82,  79,  80, 231, 232,  77,  78,\n",
              "       233, 234,  75,  76,  74,  73,  72,  71,  70,  69,  68,  67,  65,\n",
              "        66, 236, 235,  63,  64,  62,  61,  60,  59,  57,  58,  55,  56,\n",
              "        53,  54,  51,  52,  49,  50, 237, 238,  48,  47,  46,  45,  44,\n",
              "        43, 239, 240,  42,  41, 242, 241,  40,  39,  37,  38,  34,  33,\n",
              "        35,  36,  31,  32,  29,  30,  27,  28,  25,  26, 243, 244,  23,\n",
              "        24,  21,  22,  15,  16,  17,  18,  19,  20, 246, 245,  13,  14,\n",
              "         9,  10,  11,  12,   0,   8,   7,   6,   5,   4,   3,   2,   1,\n",
              "       247, 248, 249, 250, 252, 251, 253, 254, 255, 256, 257, 258, 259,\n",
              "       260, 261, 262, 264, 263, 265, 266, 267, 268, 269, 270, 271, 272,\n",
              "       273, 274, 276, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "       286, 287, 288, 290, 289, 291, 292, 293, 294, 295, 296, 297, 298,\n",
              "       299, 300, 302, 301, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
              "       312, 313, 314, 316, 315, 317, 318, 319, 320, 321, 322, 323, 324,\n",
              "       325, 326, 328, 327, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
              "       338, 340, 339, 341])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m=arr1[0]\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GCxLLrBpvxy",
        "outputId": "7073bace-c2ab-42a0-a8b7-d2ea35556466"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold1 = [1.9998832, 0.9998832, 0.9997861, 0.9997857, 0.99978286, 0.999782, 0.9997317, 0.9997291, 0.9996877, 0.99968636, 0.99966216, 0.9996612, 0.999634, 0.9996277, 0.9994647, 0.99946195, 0.99925905, 0.99925536, 0.9990922, 0.999091, 0.99886847, 0.9988619, 0.998331, 0.9983229, 0.9976526, 0.9976477, 0.997535, 0.9975273, 0.99734867, 0.9973411, 0.99720997, 0.9971878, 0.99699056, 0.9969658, 0.9964479, 0.9964431, 0.9963967, 0.99638736, 0.9963253, 0.99630296, 0.9955527, 0.9954122, 0.9952427, 0.9952165, 0.9946062, 0.99459225, 0.99365294, 0.99362844, 0.9935408, 0.9935294, 0.99336904, 0.993309, 0.9928383, 0.99273926, 0.9922854, 0.99224985, 0.9908907, 0.99088484, 0.99078244, 0.99064356, 0.9896515, 0.9896003, 0.98868716, 0.9885904, 0.9880995, 0.98808354, 0.98792726, 0.98789793, 0.9875787, 0.9875678, 0.98663867, 0.98626965, 0.9856328, 0.98554635, 0.98509663, 0.9850465, 0.9837144, 0.98365706, 0.98215806, 0.9819072, 0.98126733, 0.9812283, 0.97869176, 0.9783755, 0.9776133, 0.97743326, 0.9757627, 0.975684, 0.97520614, 0.97503835, 0.97472304, 0.97422963, 0.97353303, 0.97321665, 0.9722463, 0.9720795, 0.9695439, 0.9695347, 0.96736777, 0.9672372, 0.9632408, 0.96313477, 0.95922613, 0.95907897, 0.95842874, 0.9583067, 0.9581167, 0.9544014, 0.9526674, 0.9525858, 0.9510184, 0.95055306, 0.947246, 0.9457283, 0.9436906, 0.94353145, 0.9430381, 0.942741, 0.9423808, 0.94214666, 0.93858624, 0.9370826, 0.93484104, 0.93231213, 0.930847, 0.9300864, 0.9199783, 0.9196945, 0.91817325, 0.91640496, 0.9030632, 0.9006215, 0.89880884, 0.8976603, 0.8962467, 0.8958634, 0.8875548, 0.8858314, 0.8820869, 0.8813522, 0.87613857, 0.87206304, 0.87017196, 0.8701712, 0.8670659, 0.86047024, 0.8588393, 0.8547401, 0.8542562, 0.8532569, 0.83342874, 0.8215515, 0.8095563, 0.8080545, 0.7897555, 0.7762958, 0.7740711, 0.76575273, 0.76025313, 0.76019496, 0.7499839, 0.7493876, 0.7410195, 0.73584294, 0.73362803, 0.72977346, 0.72970444, 0.7268248, 0.6978728, 0.69682974, 0.6916758, 0.69106597, 0.6874488, 0.68672645, 0.68400365, 0.6771028, 0.6709337, 0.66038114, 0.6603037, 0.6565318, 0.6539657, 0.6446207, 0.6426046, 0.6195666, 0.61743575, 0.608996, 0.6006019, 0.59828126, 0.5965468, 0.5925526, 0.5746243, 0.5703811, 0.570332, 0.5697213, 0.56822807, 0.55533224, 0.54530615, 0.5383859, 0.51969266, 0.5094655, 0.5049325, 0.48970154, 0.48717663, 0.48290125, 0.4781911, 0.47442445, 0.47402027, 0.46549708, 0.46173823, 0.46035716, 0.46019375, 0.4564737, 0.45645684, 0.44570535, 0.4429069, 0.43591052, 0.428905, 0.41055202, 0.40861696, 0.38284934, 0.37818006, 0.3759655, 0.37073871, 0.35421652, 0.3538172, 0.31665584, 0.31524727, 0.31056246, 0.2989467, 0.29683962, 0.2952445, 0.28725696, 0.27249336, 0.2644726, 0.26144922, 0.25240624, 0.24958508, 0.24030632, 0.23830715, 0.23650023, 0.23094064, 0.22195922, 0.21752493, 0.18659614, 0.17116515, 0.16435438, 0.16261585, 0.15146996, 0.15107745, 0.1444, 0.14295138, 0.13245204, 0.12620422, 0.119879566, 0.11975165, 0.118324526, 0.11593965, 0.098186135, 0.09785242, 0.091406636, 0.090215445, 0.08418061, 0.08304632, 0.06881861, 0.06848963, 0.061489142, 0.061178267, 0.059552394, 0.059286956, 0.048197087, 0.047838267, 0.044340618, 0.043727264, 0.04219816, 0.042108282, 0.039736193, 0.038992755, 0.03801333, 0.03771559, 0.03253491, 0.032306653, 0.031146316, 0.030100254, 0.027726557, 0.027641376, 0.024242992, 0.023785178, 0.023658633, 0.022973994, 0.019192198, 0.01911575, 0.018173907, 0.01787776, 0.016579667, 0.016196815, 0.015643524, 0.015463328, 0.0130986795, 0.01307658, 0.012780818, 0.012694194, 0.011979398, 0.0119768195, 0.010616548, 0.010610101, 0.010079424, 0.010065293, 0.005130009, 0.005062563, 0.0049943924, 0.004976888, 0.004276817, 0.00417128, 0.003820923, 0.0037798402, 0.0035605968, 0.0035357468, 0.002860462, 0.0028586262, 0.0028112973, 0.0027864312, 0.0025809042, 0.002562574, 0.0021059227, 0.0021035974, 0.0019522283, 0.0019378876, 0.0018859035, 0.0018538922, 0.0018274436, 0.0018261933, 0.0011928952, 0.0011900868, 0.0010981389, 0.0010898194, 0.0009740392, 0.0009722192, 0.0008904236, 0.0008898909, 0.00047057116, 0.00047004237, 0.00034769945, 0.00034629123, 0.0001652708, 0.00016402773, 8.100818e-05]"
      ],
      "metadata": {
        "id": "El80kYf-n7FC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold1[m]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK0lraLkpe0_",
        "outputId": "e66fd230-5ed2-411b-a67e-75362a88c305"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6771028"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "200,2 data - 1 layers set reduction - cross validation without roc.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}